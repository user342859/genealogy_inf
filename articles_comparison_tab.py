"""
–ú–æ–¥—É–ª—å Streamlit-–≤–∫–ª–∞–¥–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª –ø–æ —Å—Ç–∞—Ç—å—è–º.
–ò–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –∏ –≤—ã–∑—ã–≤–∞–π—Ç–µ render_articles_comparison_tab() –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏.
"""

from __future__ import annotations

import io
import re
from typing import Callable, Dict, List, Optional, Set, Tuple

import pandas as pd
import streamlit as st

from articles_comparison import (
    DistanceMetric,
    DISTANCE_METRIC_LABELS,
    ARTICLES_HELP_TEXT,
    CLASSIFIER_LIST_TEXT,
    load_articles_data,
    prepare_articles_dataset,
    compute_article_analysis,
    create_articles_silhouette_plot,
    create_comparison_summary,
    get_code_depth,
)

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ openpyxl –¥–ª—è Excel
try:
    import openpyxl  # type: ignore
except Exception:
    openpyxl = None


# ==============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –î–ò–ê–õ–û–ì–ò/–≠–ö–°–ü–û–†–¢
# ==============================================================================

def _show_articles_instruction() -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –≤–æ –≤—Å–ø–ª—ã–≤–∞—é—â–µ–º –æ–∫–Ω–µ."""
    @st.dialog("üìñ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Å—Ç–∞—Ç—å—è–º", width="large")
    def _dlg():
        st.markdown(ARTICLES_HELP_TEXT)
    _dlg()


def _show_classifier_list() -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –≤–æ –≤—Å–ø–ª—ã–≤–∞—é—â–µ–º –æ–∫–Ω–µ."""
    @st.dialog("üóÇ –°–ø–∏—Å–æ–∫ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞", width="large")
    def _dlg():
        st.markdown(CLASSIFIER_LIST_TEXT)
    _dlg()


def _download_dataframe(df: pd.DataFrame, file_base: str) -> None:
    """–î–∏–∞–ª–æ–≥ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (CSV/XLSX)."""
    @st.dialog("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞", width="small")
    def _dlg():
        st.write("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö:")

        csv_bytes = df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
        st.download_button(
            label="üìÑ –°–∫–∞—á–∞—Ç—å CSV",
            data=csv_bytes,
            file_name=f"{file_base}.csv",
            mime="text/csv",
            use_container_width=True,
        )

        if openpyxl is None:
            st.warning("–î–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Excel —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç `openpyxl`.")
            return

        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
            df.to_excel(writer, index=False)
        st.download_button(
            label="üìä –°–∫–∞—á–∞—Ç—å Excel (XLSX)",
            data=buffer.getvalue(),
            file_name=f"{file_base}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )
    _dlg()


# ==============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø UI
# ==============================================================================

_CODE_RE = re.compile(r"^[\d\.]+$")


def _code_sort_key(code: str) -> Tuple[int, ...]:
    """–°—Ç–∞–±–∏–ª—å–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∫–æ–¥–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: '10.2' > '2.9' (–ø–æ —á–∏—Å–ª–∞–º, –Ω–µ –ø–æ —Å—Ç—Ä–æ–∫–∞–º)."""
    try:
        return tuple(int(p) for p in code.split(".") if p != "")
    except Exception:
        # fallback: —Å—Ç—Ä–æ–∫–æ–≤–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
        return tuple([10**9])


def _extract_classifier_codes(df_articles: pd.DataFrame) -> List[str]:
    """–ë–µ—Ä—ë—Ç –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –∫–æ–¥–∞–º–∏ (—Ü–∏—Ñ—Ä—ã/—Ç–æ—á–∫–∏) –∏–∑ –±–∞–∑—ã —Å—Ç–∞—Ç–µ–π."""
    cols = df_articles.columns.tolist()
    codes = [c for c in cols if isinstance(c, str) and _CODE_RE.match(c)]
    return codes


def _build_selectable_nodes(codes: List[str], max_depth: int = 3) -> List[str]:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —É–∑–ª–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞:
    - –£—Ä–æ–≤–Ω–∏ 1..max_depth (–ø—Ä–µ—Ñ–∏–∫—Å—ã –∫–æ–¥–æ–≤).
    """
    nodes: Set[str] = set()
    for c in codes:
        parts = c.split(".")
        depth = min(len(parts), max_depth)
        for d in range(1, depth + 1):
            nodes.add(".".join(parts[:d]))
    return sorted(nodes, key=_code_sort_key)


def _basis_label(code: str, classifier_labels: Dict[str, str]) -> str:
    if code == "__ALL__":
        return "–í—Å–µ —Ä–∞–∑–¥–µ–ª—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"
    if code == "__YEAR__":
        return "–ì–æ–¥"
    label = classifier_labels.get(code, "")
    indent = " " * max(0, (get_code_depth(code) - 1) * 2)
    if label:
        return f"{indent}{code} {label}"
    return f"{indent}{code}"


def _basis_to_feature_keys(
    selected_basis: List[str],
    selectable_nodes: List[str],
) -> Optional[List[str]]:
    """
    –ú–∞–ø–∏—Ç UI-–≤—ã–±–æ—Ä –Ω–∞ selected_features_keys –¥–ª—è prepare_articles_dataset().

    –õ–æ–≥–∏–∫–∞:
    - –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω '__ALL__' –±–µ–∑ –≥–æ–¥–∞ -> None (–≤—Å–µ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –±–µ–∑ Year).
    - –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω '__ALL__' + –≥–æ–¥ -> top-level —É–∑–ª—ã + ['Year'] (–≤—Å–µ —Ç–µ–º—ã + Year).
    - –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–æ–¥—ã -> —ç—Ç–∏ –∫–æ–¥—ã, –ø–ª—é—Å 'Year' –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –≥–æ–¥–∞.
    - –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω —Ç–æ–ª—å–∫–æ –≥–æ–¥ -> ['Year'].
    """
    include_all = "__ALL__" in selected_basis
    include_year = "__YEAR__" in selected_basis
    chosen_nodes = [x for x in selected_basis if x not in ("__ALL__", "__YEAR__")]

    if include_all:
        if include_year:
            top_level = sorted({n.split(".")[0] for n in selectable_nodes if n}, key=_code_sort_key)
            return top_level + ["Year"]
        # –≤—Å–µ —Ç–µ–º—ã, –Ω–æ –±–µ–∑ –≥–æ–¥–∞
        return None

    # –ë–µ–∑ ALL: –ª–∏–±–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —É–∑–ª—ã, –ª–∏–±–æ —Ç–æ–ª—å–∫–æ –≥–æ–¥
    keys: List[str] = []
    keys.extend(chosen_nodes)
    if include_year:
        keys.append("Year")

    if not keys:
        # –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ -> –ø–æ —Å–º—ã—Å–ª—É "–≤—Å–µ —Ç–µ–º—ã" (–±–µ–∑ –≥–æ–¥–∞)
        return None

    return keys


# ==============================================================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –í–ö–õ–ê–î–ö–ò
# ==============================================================================

def render_articles_comparison_tab(
    df: Optional[pd.DataFrame] = None,
    idx: Optional[Dict[str, Set[int]]] = None,
    lineage_func: Optional[Callable] = None,
    selected_roots: Optional[List[str]] = None,
    classifier_labels: Optional[Dict[str, str]] = None,
    *,
    # –ê–ª–∏–∞—Å—ã –ø–æ–¥ –≤—ã–∑–æ–≤ –∏–∑ streamlit_app.py
    df_lineage: Optional[pd.DataFrame] = None,
    idx_lineage: Optional[Dict[str, Set[int]]] = None,
) -> None:
    """
    –†–µ–Ω–¥–µ—Ä–∏—Ç –≤–∫–ª–∞–¥–∫—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —à–∫–æ–ª –ø–æ —Å—Ç–∞—Ç—å—è–º.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –≤—ã–∑–æ–≤–∞:
    - render_articles_comparison_tab(df=..., idx=..., ...)
    - render_articles_comparison_tab(df_lineage=..., idx_lineage=..., ...)  (–∫–∞–∫ –≤ streamlit_app.py)
    """
    # --- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å) ---
    if df is None and df_lineage is not None:
        df = df_lineage
    if idx is None and idx_lineage is not None:
        idx = idx_lineage

    if selected_roots is None:
        selected_roots = []
    if classifier_labels is None:
        classifier_labels = {}

    # --- –í–≤–µ—Ä—Ö–Ω–∏–µ –∫–Ω–æ–ø–∫–∏ –ø–æ–º–æ—â–∏ ---
    c1, c2, _ = st.columns([0.22, 0.28, 0.50])
    with c1:
        if st.button("üìñ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", key="art_help_btn"):
            _show_articles_instruction()
    with c2:
        if st.button("üóÇ –°–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞", key="art_class_btn"):
            _show_classifier_list()

    st.header("üî¨ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª –ø–æ –ø—É–±–ª–∏–∫–∞—Ü–∏—è–º")

    # --- –ü—Ä–µ–¥—É—Å–ª–æ–≤–∏—è ---
    if lineage_func is None or df is None or idx is None:
        st.error("‚ùå –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ–∞–ª–æ–≥–∏–∏ (df/idx/lineage_func).")
        return

    if len(selected_roots) < 2:
        st.warning(
            "‚ö†Ô∏è –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤—ã–±–µ—Ä–∏—Ç–µ **–º–∏–Ω–∏–º—É–º –¥–≤—É—Ö** —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π –Ω–∞ –≤–∫–ª–∞–¥–∫–µ ¬´–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ä–µ–≤—å–µ–≤¬ª "
            "–∏ –Ω–∞–∂–º–∏—Ç–µ —Ç–∞–º –∫–Ω–æ–ø–∫—É ¬´–ü–æ—Å—Ç—Ä–æ–∏—Ç—å¬ª."
        )
        return

    df_articles = load_articles_data()
    if df_articles is None or df_articles.empty:
        st.error("‚ùå –ë–∞–∑–∞ —Å—Ç–∞—Ç–µ–π (`articles_scores.csv`) –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –ø—É—Å—Ç–∞.")
        return

    st.success(f"–í—ã–±—Ä–∞–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {', '.join(selected_roots)}")
    st.divider()

    # --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ---
    col_cfg1, col_cfg2 = st.columns(2)

    with col_cfg1:
        st.subheader("üìê –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞")

        scope = st.radio(
            "–û—Ö–≤–∞—Ç —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —à–∫–æ–ª—ã:",
            options=["direct", "all"],
            format_func=lambda x: "–¢–æ–ª—å–∫–æ –ø—Ä—è–º—ã–µ —É—á–µ–Ω–∏–∫–∏ (1-–π —É—Ä–æ–≤–µ–Ω—å)" if x == "direct" else "–í—Å–µ –ø–æ–∫–æ–ª–µ–Ω–∏—è —à–∫–æ–ª—ã (–≥–µ–Ω–µ–∞–ª–æ–≥–∏—è)",
            key="art_scope_choice",
        )

        metric_choice: DistanceMetric = st.selectbox(
            "–ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è:",
            options=list(DISTANCE_METRIC_LABELS.keys()),
            format_func=lambda x: DISTANCE_METRIC_LABELS[x],
            key="art_metric_choice",
        )

    with col_cfg2:
        st.subheader("üéØ –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±–∞–∑–∏—Å")

        codes_in_df = _extract_classifier_codes(df_articles)
        selectable_nodes = _build_selectable_nodes(codes_in_df, max_depth=3)

        basis_options = ["__ALL__", "__YEAR__"] + selectable_nodes

        selected_basis = st.multiselect(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª—ã –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:",
            options=basis_options,
            default=["__ALL__"],
            format_func=lambda x: _basis_label(x, classifier_labels),
            key="art_basis_selection",
        )

    decay_factor = 0.5
    if str(metric_choice).endswith("_oblique"):
        decay_factor = st.slider(
            "–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è (decay):",
            min_value=0.1,
            max_value=0.9,
            value=0.5,
            step=0.1,
            help="–í–ª–∏—è–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏—Ö —Å–≤—è–∑–µ–π (–∫–æ—Å–æ—É–≥–æ–ª—å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞).",
            key="art_decay_slider",
        )

    st.divider()

    # --- –ó–∞–ø—É—Å–∫ ---
    if not st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", type="primary", key="art_run_btn"):
        return

    selected_features_keys = _basis_to_feature_keys(selected_basis, selectable_nodes)

    with st.spinner("–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫..."):
        dataset, used_features = prepare_articles_dataset(
            roots=selected_roots,
            df_lineage=df,
            idx_lineage=idx,
            lineage_func=lineage_func,
            df_articles=df_articles,
            scope=scope,
            selected_features_keys=selected_features_keys,
        )

    if dataset is None or dataset.empty:
        st.error("‚ùå –ü–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º —Å—Ç–∞—Ç—å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return

    # --- –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è —à–∫–æ–ª ---
    counts = dataset["school"].value_counts(dropna=False)
    present_schools = [s for s in selected_roots if s in counts.index and counts[s] > 0]

    with st.expander("üîé –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: —Å–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π –ø–æ–ø–∞–ª–æ –≤ –∫–∞–∂–¥—É—é —à–∫–æ–ª—É", expanded=False):
        diag_df = pd.DataFrame({"–®–∫–æ–ª–∞": selected_roots, "–°—Ç–∞—Ç–µ–π –≤ –≤—ã–±–æ—Ä–∫–µ": [int(counts.get(s, 0)) for s in selected_roots]})
        st.dataframe(diag_df, use_container_width=True, hide_index=True)

    if len(present_schools) < 2:
        st.error(
            "‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: —Å—Ç–∞—Ç—å–∏ –Ω–∞–π–¥–µ–Ω—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–¥–Ω–æ–π —à–∫–æ–ª—ã. "
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–π –æ—Ö–≤–∞—Ç (–≤—Å–µ –ø–æ–∫–æ–ª–µ–Ω–∏—è) –∏–ª–∏ –¥—Ä—É–≥–æ–π –Ω–∞–±–æ—Ä —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π."
        )
        with st.expander("üìÑ –°—Ç–∞—Ç—å–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ (–¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏)", expanded=False):
            view_df = dataset[["Article_id", "school", "Authors", "Title", "Year"]].copy()
            view_df.columns = ["ID", "–®–∫–æ–ª–∞", "–ê–≤—Ç–æ—Ä—ã", "–ó–∞–≥–æ–ª–æ–≤–æ–∫", "–ì–æ–¥"]
            st.dataframe(view_df, use_container_width=True, hide_index=True)
        return

    # --- –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ ---
    with st.spinner("–†–∞—Å—á—ë—Ç —Å–∏–ª—É—ç—Ç–∞ –∏ –ø—Ä–æ—á–∏—Ö –º–µ—Ç—Ä–∏–∫..."):
        results = compute_article_analysis(
            dataset=dataset,
            used_features=used_features,
            metric_choice=metric_choice,
            decay_factor=decay_factor,
        )

    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")

    m1, m2, m3 = st.columns(3)
    with m1:
        st.metric("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∏–ª—É—ç—Ç–∞", f"{results['silhouette_avg']:.3f}")
        st.caption("–°—Ç–µ–ø–µ–Ω—å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π —à–∫–æ–ª (–æ—Ç -1 –¥–æ 1).")
    with m2:
        db = results.get("davies_bouldin")
        st.metric("–ò–Ω–¥–µ–∫—Å –î—ç–≤–∏—Å–∞‚Äì–ë–æ—É–ª–¥–∏–Ω–∞", f"{db:.3f}" if isinstance(db, (float, int)) else "‚Äî")
        st.caption("–ú–µ–Ω—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–±—ã—á–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –±–æ–ª–µ–µ —á—ë—Ç–∫–æ–º—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é.")
    with m3:
        ch = results.get("calinski_harabasz")
        st.metric("–ò–Ω–¥–µ–∫—Å –ö–∞–ª–∏–Ω—Å–∫–æ–≥–æ‚Äì–•–∞—Ä–∞–±–∞–∑–∞", f"{int(ch)}" if isinstance(ch, (float, int)) else "‚Äî")
        st.caption("–ë–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–±—ã—á–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –±–æ–ª–µ–µ —á—ë—Ç–∫–æ–º—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é.")

    st.markdown("### üìà –ì—Ä–∞—Ñ–∏–∫ —Å–∏–ª—É—ç—Ç–∞")
    fig = create_articles_silhouette_plot(
        sample_scores=results["sample_silhouette_values"],
        labels=results["labels"],
        school_order=results["school_order"],
        overall_score=results["silhouette_avg"],
        metric_label=DISTANCE_METRIC_LABELS[metric_choice],
    )
    st.pyplot(fig)

    # --- –¶–µ–Ω—Ç—Ä–æ–∏–¥—ã ---
    school_order = results.get("school_order", [])
    centroids_dist = results.get("centroids_dist")
    if isinstance(school_order, list) and len(school_order) == 2 and isinstance(centroids_dist, (float, int)):
        st.info(f"**–ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º–∏ —à–∫–æ–ª:** {centroids_dist:.3f}")
    elif isinstance(school_order, list) and len(school_order) > 2 and centroids_dist is not None:
        with st.expander("–ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º–∏", expanded=False):
            dist_df = pd.DataFrame(centroids_dist, index=school_order, columns=school_order)
            st.dataframe(dist_df, use_container_width=True)

    # --- –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ ---
    st.markdown("### üìã –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    summary_df = create_comparison_summary(dataset, used_features)
    st.dataframe(summary_df, use_container_width=True, hide_index=True)

    if st.button("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", key="art_dl_btn"):
        _download_dataframe(summary_df, "articles_comparison_stats")

    with st.expander("üìÑ –°–ø–∏—Å–æ–∫ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π", expanded=False):
        view_df = dataset[["Article_id", "school", "Authors", "Title", "Year"]].copy()
        view_df.columns = ["ID", "–®–∫–æ–ª–∞", "–ê–≤—Ç–æ—Ä—ã", "–ó–∞–≥–æ–ª–æ–≤–æ–∫", "–ì–æ–¥"]
        st.dataframe(view_df, use_container_width=True, hide_index=True)

"""
articles_comparison_tab.py

Streamlit-–≤–∫–ª–∞–¥–∫–∞: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª/–∞–≤—Ç–æ—Ä–æ–≤ –ø–æ –ø—É–±–ª–∏–∫–∞—Ü–∏—è–º (articles_scores.csv).
"""

from __future__ import annotations

import io
import re
from typing import Any, Callable, Dict, List, Optional, Set, Tuple

import pandas as pd
import streamlit as st

from articles_comparison import (
    DistanceMetric,
    DISTANCE_METRIC_LABELS,
    ARTICLES_HELP_TEXT,
    CLASSIFIER_LIST_TEXT,
    load_articles_data,
    load_articles_classifier,
    compute_article_analysis,
    create_articles_silhouette_plot,
    create_comparison_summary,
    get_code_depth,
)

# optional
try:
    import openpyxl  # type: ignore
except Exception:
    openpyxl = None

# ------------------------------------------------------------------------------
# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# ------------------------------------------------------------------------------
AUTHOR_COLUMN = "candidate_name"

# ------------------------------------------------------------------------------
# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω
# ------------------------------------------------------------------------------
_RE_MULTI_SPACE = re.compile(r"\s+")
_RE_DOTS_SPACES = re.compile(r"\s*\.\s*")
_RE_INIT_SPACES = re.compile(r"([A-Za-z–ê-–Ø–∞-—è])\.\s+([A-Za-z–ê-–Ø–∞-—è])\.")

def _canon_initials(name: str) -> str:
    """–ü—Ä–∏–≤–æ–¥–∏—Ç '–ö–∞—Ä–∞–∫–æ–∑–æ–≤ –°. –î.' –∫ –µ–¥–∏–Ω–æ–º—É –≤–∏–¥—É: '–∫–∞—Ä–∞–∫–æ–∑–æ–≤ —Å.–¥.'"""
    if not isinstance(name, str):
        return ""
    s = name.strip()
    if not s:
        return ""
    s = _RE_MULTI_SPACE.sub(" ", s)
    s = _RE_DOTS_SPACES.sub(".", s)
    s = _RE_INIT_SPACES.sub(r"\1.\2.", s)
    s = _RE_MULTI_SPACE.sub(" ", s)
    return s.lower()

def _display_initials(canon_key: str) -> str:
    """'–∫–∞—Ä–∞–∫–æ–∑–æ–≤ —Å.–¥.' -> '–ö–∞—Ä–∞–∫–æ–∑–æ–≤ –°.–î.'"""
    if not isinstance(canon_key, str):
        return ""
    s = canon_key.strip()
    if not s:
        return ""
    parts = s.split(maxsplit=1)
    if len(parts) == 1:
        return parts[0].title()
    surname, init = parts[0], parts[1]
    return f"{surname.title()} {init.upper()}".strip()

def _fio_to_short(full_name: str) -> str:
    """'–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á' -> '–ò–≤–∞–Ω–æ–≤ –ò.–ò.'"""
    if not isinstance(full_name, str):
        return ""
    s = full_name.strip()
    if not s:
        return ""
    s = s.replace(".", " ")
    parts = [p for p in s.split() if p]
    if not parts:
        return ""
    surname = parts[0]
    initials = ""
    if len(parts) >= 2:
        initials += parts[1][0] + "."
    if len(parts) >= 3:
        initials += parts[2][0] + "."
    return f"{surname} {initials}".strip()

def _is_initials_only_option(label: str) -> bool:
    """–≠–≤—Ä–∏—Å—Ç–∏–∫–∞: '–§–∞–º–∏–ª–∏—è –ò.–û.' vs '–§–∞–º–∏–ª–∏—è –ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ'."""
    if not isinstance(label, str):
        return False
    s = label.strip()
    if not s:
        return False
    if s.count(".") >= 2 and len(s.split()) <= 2:
        return True
    return False

# ------------------------------------------------------------------------------
# –ß—Ç–µ–Ω–∏–µ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ "—Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö"
# ------------------------------------------------------------------------------
def _supervisor_columns(df_lineage: pd.DataFrame) -> List[str]:
    """–ö–æ–ª–æ–Ω–∫–∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π."""
    return [
        col for col in df_lineage.columns
        if "supervisor" in col.lower() and "name" in col.lower()
    ]

@st.cache_data(show_spinner=False)
def _extract_authors_initials_from_articles() -> Set[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏—Ö '—Ñ–∞–º–∏–ª–∏—è –∏.–æ.' –ø–æ –≤—Å–µ–º —Å—Ç–∞—Ç—å—è–º."""
    df_articles = load_articles_data()
    if df_articles is None or df_articles.empty or "Authors" not in df_articles.columns:
        return set()
    authors_set: Set[str] = set()
    for raw in df_articles["Authors"].dropna().astype(str).tolist():
        for part in re.split(r"[;]", raw):
            c = _canon_initials(part)
            if c:
                authors_set.add(c)
    return authors_set

@st.cache_data(show_spinner=False)
def _build_initials_to_fullnames(df_lineage: pd.DataFrame) -> Dict[str, List[str]]:
    """–°—Ç—Ä–æ–∏—Ç –∏–Ω–¥–µ–∫—Å: canon('–∏–≤–∞–Ω–æ–≤ –∏.–∏.') -> ['–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á', ...]"""
    names: Set[str] = set()

    if AUTHOR_COLUMN in df_lineage.columns:
        names.update(
            str(v).strip() for v in df_lineage[AUTHOR_COLUMN].dropna().astype(str).tolist()
            if str(v).strip()
        )

    for col in _supervisor_columns(df_lineage):
        names.update(
            str(v).strip() for v in df_lineage[col].dropna().astype(str).tolist()
            if str(v).strip()
        )

    mapping: Dict[str, List[str]] = {}
    for full in names:
        short = _fio_to_short(full)
        key = _canon_initials(short)
        if not key:
            continue
        mapping.setdefault(key, [])
        if full not in mapping[key]:
            mapping[key].append(full)

    for k in list(mapping.keys()):
        mapping[k] = sorted(mapping[k])
    return mapping

@st.cache_data(show_spinner=False)
def _compute_selectable_people(
    df_lineage: pd.DataFrame,
    include_without_descendants: bool,
) -> Tuple[List[str], Dict[str, str]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç options –∏ meta –¥–ª—è multiselect."""
    authors_in_articles = _extract_authors_initials_from_articles()
    initials_to_full = _build_initials_to_fullnames(df_lineage)

    supervisor_cols = _supervisor_columns(df_lineage)
    leaders: Set[str] = set()
    for col in supervisor_cols:
        leaders.update(
            str(v).strip() for v in df_lineage[col].dropna().astype(str).unique()
            if str(v).strip()
        )

    leader_options: List[str] = []
    for full in sorted(leaders):
        key = _canon_initials(_fio_to_short(full))
        if key and key in authors_in_articles:
            leader_options.append(full)

    meta: Dict[str, str] = {o: "leader" for o in leader_options}

    if not include_without_descendants:
        return leader_options, meta

    all_fullnames: Set[str] = set()
    for fulls in initials_to_full.values():
        all_fullnames.update(fulls)

    person_no_desc: List[str] = []
    for full in sorted(all_fullnames):
        if full in leaders:
            continue
        key = _canon_initials(_fio_to_short(full))
        if key and key in authors_in_articles:
            person_no_desc.append(full)

    for o in person_no_desc:
        meta[o] = "person_no_desc"

    initials_only: List[str] = []
    initials_amb: List[str] = []
    for key in sorted(authors_in_articles):
        fulls = initials_to_full.get(key, [])
        if len(fulls) == 0:
            display = _display_initials(key)
            initials_only.append(display)
            meta[display] = "initials_only"
        elif len(fulls) > 1:
            display = _display_initials(key)
            initials_amb.append(display)
            meta[display] = "initials_ambiguous"

    options = [*leader_options, *person_no_desc, *initials_only, *initials_amb]
    return options, meta

# ------------------------------------------------------------------------------
# –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û—Ç–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —É–∑–ª–∞–º
# ------------------------------------------------------------------------------
def _filter_feature_columns(all_feature_cols: List[str], selected_nodes: List[str]) -> List[str]:
    """
    selected_nodes: —Å–ø–∏—Å–æ–∫ —É–∑–ª–æ–≤ –≤–∏–¥–∞ ["1.1", "2.3.4", "–ì–æ–¥"].
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫-—Å–∫–æ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ø–∞–¥–∞—é—Ç –ø–æ–¥ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —É–∑–ª—ã.

    –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∏ –≤—ã–±–æ—Ä–µ —Ç–æ–ª—å–∫–æ "–ì–æ–¥" –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å ['Year_num'] –±–µ–∑ —Ç–µ–º–∞—Ç–∏–∫–∏.
    """
    if not selected_nodes:
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ
        return all_feature_cols

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—ã–±—Ä–∞–Ω –ª–∏ "–ì–æ–¥"
    include_year = any(n.lower() in ("–≥–æ–¥", "year", "year_num") for n in selected_nodes)

    # –í—ã–¥–µ–ª–∏–º —Ç–æ–ª—å–∫–æ –∫–æ–¥—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (—Ü–∏—Ñ—Ä—ã –∏ —Ç–æ—á–∫–∏)
    nodes = [n for n in selected_nodes if re.match(r"^[\d\.]+$", n)]

    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –µ—Å–ª–∏ nodes –ø—É—Å—Ç–æ–π (—Ç–æ–ª—å–∫–æ Year –≤—ã–±—Ä–∞–Ω), –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ Year_num
    if not nodes:
        return ["Year_num"] if include_year else []

    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏
    picked: Set[str] = set()
    for col in all_feature_cols:
        if col == "Year_num":
            continue  # –ì–æ–¥ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
        if not re.match(r"^[\d\.]+$", col):
            continue
        for n in nodes:
            if col == n or col.startswith(n + "."):
                picked.add(col)
                break

    result = sorted(picked)

    # –î–æ–±–∞–≤–ª—è–µ–º –≥–æ–¥ –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω
    if include_year:
        result.append("Year_num")

    return result

def _format_node_option(code: str, classifier_dict: Dict[str, str]) -> str:
    depth = get_code_depth(code)
    indent = "  " * max(0, depth - 1)
    title = classifier_dict.get(code, "")
    if title:
        return f"{indent}{code} ‚Äî {title}"
    return f"{indent}{code}"

# ------------------------------------------------------------------------------
# –≠–∫—Å–ø–æ—Ä—Ç
# ------------------------------------------------------------------------------
def _download_dataframe(df: pd.DataFrame, filename_stem: str) -> None:
    """–ü—Ä–æ—Å—Ç–æ–π —ç–∫—Å–ø–æ—Ä—Ç: Excel –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ openpyxl, –∏–Ω–∞—á–µ CSV."""
    if df is None or df.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏.")
        return

    if openpyxl is not None:
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="results")
        st.download_button(
            "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å Excel",
            data=buf.getvalue(),
            file_name=f"{filename_stem}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )
    else:
        csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å CSV",
            data=csv_bytes,
            file_name=f"{filename_stem}.csv",
            mime="text/csv",
            use_container_width=True,
        )

# ------------------------------------------------------------------------------
# –î–∏–∞–ª–æ–≥–∏
# ------------------------------------------------------------------------------
def _show_articles_instruction() -> None:
    @st.dialog("üìñ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Å—Ç–∞—Ç—å—è–º", width="large")
    def _dlg():
        st.markdown(ARTICLES_HELP_TEXT)
    _dlg()

def _show_classifier_list() -> None:
    @st.dialog("üß≠ –°–ø–∏—Å–æ–∫ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞", width="large")
    def _dlg():
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è —Å—Ç–∞—Ç–µ–π
        classifier = load_articles_classifier()
        if classifier:
            md_text = "### –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è —Å—Ç–∞—Ç–µ–π\n\n"
            for code in sorted(classifier.keys(), key=lambda x: (get_code_depth(x), x)):
                depth = get_code_depth(code)
                indent = "  " * (depth - 1)
                md_text += f"{indent}**{code}** ‚Äî {classifier[code]}\n\n"
            st.markdown(md_text)
        else:
            st.markdown(CLASSIFIER_LIST_TEXT)
    _dlg()

def _show_disambiguation_dialog(ambiguous: Dict[str, List[str]]) -> None:
    """
    ambiguous: canon_initials -> list(full_fio)
    –ó–∞–ø–∏—à–µ—Ç –≤—ã–±–æ—Ä –≤ st.session_state["ac_disambiguation"].
    """
    @st.dialog("‚ö†Ô∏è –£—Ç–æ—á–Ω–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∞–≤—Ç–æ—Ä–∞ (–∏–Ω–∏—Ü–∏–∞–ª—ã ‚Üí –ø–æ–ª–Ω–æ–µ –§–ò–û)", width="large")
    def _dlg():
        st.markdown(
            "–î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤ –≤ `articles_scores.csv` –∏–Ω–∏—Ü–∏–∞–ª—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å—Ä–∞–∑—É —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ "
            "–ø–æ–ª–Ω—ã–º–∏ –§–ò–û –≤ –±–∞–∑–µ. –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –§–ò–û –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ "
            "–∏–ª–∏ –æ—Ç–∫–∞–∂–∏—Ç–µ—Å—å –æ—Ç –∞–Ω–∞–ª–∏–∑–∞."
        )

        choices: Dict[str, str] = {}
        for init_key, fulls in ambiguous.items():
            label = _display_initials(init_key)
            opts = ["‚Äî –û—Ç–∫–∞–∑–∞—Ç—å—Å—è –æ—Ç –∞–Ω–∞–ª–∏–∑–∞ ‚Äî", *fulls]
            choice = st.selectbox(
                f"–ê–≤—Ç–æ—Ä: **{label}**",
                options=opts,
                key=f"ac_pick_{init_key}",
            )
            choices[init_key] = choice

        col1, col2 = st.columns(2)
        with col1:
            if st.button("‚úÖ –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å", type="primary", use_container_width=True):
                if any(v.startswith("‚Äî") for v in choices.values()):
                    st.session_state["ac_abort"] = True
                    st.session_state["ac_disambiguation"] = {}
                else:
                    st.session_state["ac_abort"] = False
                    st.session_state["ac_disambiguation"] = choices
                st.session_state["ac_run_after_disambiguation"] = True
                st.rerun()
        with col2:
            if st.button("‚ùå –û—Ç–º–µ–Ω–∞", use_container_width=True):
                st.session_state["ac_abort"] = True
                st.session_state["ac_disambiguation"] = {}
                st.rerun()

    _dlg()

# ------------------------------------------------------------------------------
# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
# ------------------------------------------------------------------------------
def _build_articles_dataset(
    selected_options: List[str],
    options_meta: Dict[str, str],
    df_lineage: pd.DataFrame,
    idx_lineage: Dict[str, Set[int]],
    lineage_func: Callable,
    df_articles: pd.DataFrame,
    scope: str,
) -> pd.DataFrame:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å–æ —Å—Ç–∞—Ç—å—è–º–∏."""
    if df_articles is None or df_articles.empty:
        return pd.DataFrame()

    work_articles = df_articles.copy()
    if "Year" in work_articles.columns:
        work_articles["Year_num"] = pd.to_numeric(work_articles["Year"], errors="coerce").fillna(0)
    else:
        work_articles["Year_num"] = 0

    if "_authors_set" not in work_articles.columns:
        work_articles["_authors_set"] = work_articles["Authors"].astype(str).apply(
            lambda s: {_canon_initials(x) for x in re.split(r"[;]", s) if _canon_initials(x)}
        )

    initials_to_full = _build_initials_to_fullnames(df_lineage)
    combined: List[pd.DataFrame] = []

    for opt in selected_options:
        kind = options_meta.get(opt, "")
        school_label = opt

        members_initials: Set[str] = set()
        if kind in ("leader", "person_no_desc"):
            root_full = opt
            if scope == "direct" or scope == "all":
                try:
                    G, _ = lineage_func(df_lineage, idx_lineage, root_full)
                except TypeError:
                    G, _ = lineage_func(df_lineage, idx_lineage, root_full)
                if G is not None and getattr(G, "has_node", lambda _: False)(root_full):
                    if scope == "direct":
                        names = set(getattr(G, "successors")(root_full))
                        names.add(root_full)
                    else:
                        names = set(getattr(G, "nodes")())
                        names.add(root_full)
                else:
                    names = {root_full}
            else:
                names = {root_full}

            members_initials = {_canon_initials(_fio_to_short(n)) for n in names if _fio_to_short(n)}
            members_initials = {m for m in members_initials if m}

        elif kind in ("initials_only", "initials_ambiguous"):
            init_key = _canon_initials(opt)
            resolved = st.session_state.get("ac_disambiguation", {}).get(init_key)
            if resolved:
                school_label = resolved
                members_initials = {_canon_initials(_fio_to_short(resolved))}
            else:
                members_initials = {init_key}

        else:
            init_key = _canon_initials(opt)
            members_initials = {init_key} if init_key else set()

        if not members_initials:
            continue

        mask = work_articles["_authors_set"].apply(lambda s: not s.isdisjoint(members_initials))
        sub = work_articles[mask].copy()

        if sub.empty:
            continue

        sub["school"] = school_label
        combined.append(sub)

    if not combined:
        return pd.DataFrame()

    out = pd.concat(combined, ignore_index=True)

    if "_authors_set" in out.columns:
        out = out.drop(columns=["_authors_set"], errors="ignore")

    return out

# ------------------------------------------------------------------------------
# –û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–Ω–¥–µ—Ä
# ------------------------------------------------------------------------------
def render_articles_comparison_tab(
    df_lineage: pd.DataFrame,
    idx_lineage: Dict[str, Set[int]],
    lineage_func: Callable,
    selected_roots: Optional[List[str]] = None,
    classifier_labels: Optional[Dict[str, str]] = None,
) -> None:
    """
    –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –≤–∫–ª–∞–¥–∫—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–æ —Å—Ç–∞—Ç—å—è–º.

    –ò–ó–ú–ï–ù–ï–ù–ò–ï: classifier_labels —Ç–µ–ø–µ—Ä—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ articles_classifier.json
    """
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç–∞—Ç–µ–π –≤–º–µ—Å—Ç–æ –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ
    if classifier_labels is None:
        classifier_labels = load_articles_classifier()

    # –ü—Ä–æ–ª–æ–≥ / –∫–Ω–æ–ø–∫–∏ –ø–æ–º–æ—â–∏
    top_left, top_right = st.columns([1, 1])
    with top_left:
        st.markdown("### üî¨ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Å—Ç–∞—Ç—å—è–º")
    with top_right:
        c1, c2 = st.columns(2)
        with c1:
            if st.button("üìñ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", key="ac_help_btn"):
                _show_articles_instruction()
        with c2:
            if st.button("üß≠ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä", key="ac_classifier_btn"):
                _show_classifier_list()

    # –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –≤—ã–±–æ—Ä —à–∫–æ–ª/–∞–≤—Ç–æ—Ä–æ–≤
    st.markdown("---")
    st.markdown("### üë• –í—ã–±–æ—Ä –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")

    include_without_desc = st.checkbox(
        "–†–∞–∑—Ä–µ—à–∏—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π —Ä–∞–±–æ—Ç –∞–≤—Ç–æ—Ä–æ–≤, –¥–∞–Ω–Ω—ã–µ –æ –¥–∏—Å—Å–µ—Ä—Ç–∞–Ω—Ç–∞—Ö –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –±–∞–∑–µ",
        value=st.session_state.get("ac_include_without_desc", False),
        key="ac_include_without_desc",
        help=(
            "–ï—Å–ª–∏ –≤—ã–∫–ª—é—á–µ–Ω–æ ‚Äî –¥–æ—Å—Ç—É–ø–Ω—ã —Ç–æ–ª—å–∫–æ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –¥–∏—Å—Å–µ—Ä—Ç–∞–Ω—Ç—ã –≤ –±–∞–∑–µ.\n\n"
            "–ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ ‚Äî –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã (–∞) –ª—é–¥–∏ –∏–∑ –±–∞–∑—ã –±–µ–∑ –¥–∏—Å—Å–µ—Ä—Ç–∞–Ω—Ç–æ–≤ –∏ (–±) –∞–≤—Ç–æ—Ä—ã –∏–∑ "
            "`articles_scores.csv`, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –±–∞–∑–µ (–æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –∫–∞–∫ '–§–∞–º–∏–ª–∏—è –ò.–û.')."
        ),
    )

    options, options_meta = _compute_selectable_people(df_lineage, include_without_descendants=include_without_desc)

    if not options:
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π/–∞–≤—Ç–æ—Ä–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")
        return

    # initial default
    if "ac_selected_options" not in st.session_state:
        st.session_state["ac_selected_options"] = []
        if selected_roots:
            st.session_state["ac_selected_options"] = [r for r in selected_roots if r in options]

    selected_options = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª (–º–∏–Ω–∏–º—É–º 2)",
        options=options,
        default=st.session_state.get("ac_selected_options", []),
        key="ac_selected_options",
        help=(
            "–°–ø–∏—Å–æ–∫ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω —Ç–µ–º–∏, —á—å–∏ '–§–∞–º–∏–ª–∏—è –ò.–û.' –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ articles_scores.csv.\n\n"
            "–≠–ª–µ–º–µ–Ω—Ç—ã –≤–∏–¥–∞ '–§–∞–º–∏–ª–∏—è –ò.–û.' ‚Äî –∞–≤—Ç–æ—Ä—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –±–∞–∑–µ –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏–π."
        ),
    )

    if len(selected_options) < 2:
        st.warning("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ –º–∏–Ω–∏–º—É–º 2 —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π/–∞–≤—Ç–æ—Ä–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")
        return

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞
    st.markdown("---")
    col_params1, col_params2 = st.columns(2)

    with col_params1:
        st.markdown("### üìê –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞")

        scope = st.radio(
            "–û—Ö–≤–∞—Ç —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —à–∫–æ–ª—ã",
            options=["direct", "all"],
            format_func=lambda v: "–¢–æ–ª—å–∫–æ –ø—Ä—è–º—ã–µ —É—á–µ–Ω–∏–∫–∏ (1-–π —É—Ä–æ–≤–µ–Ω—å)" if v == "direct" else "–í—Å–µ –ø–æ–∫–æ–ª–µ–Ω–∏—è —à–∫–æ–ª—ã (–≥–µ–Ω–µ–∞–ª–æ–≥–∏—è)",
            index=0,
            key="ac_scope",
        )

        metric_options = list(DISTANCE_METRIC_LABELS.keys())
        metric_idx = st.selectbox(
            "–ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è",
            options=list(range(len(metric_options))),
            format_func=lambda i: DISTANCE_METRIC_LABELS[metric_options[i]],
            index=metric_options.index("euclidean_orthogonal") if "euclidean_orthogonal" in metric_options else 0,
            key="ac_metric",
        )
        metric_choice: DistanceMetric = metric_options[metric_idx]

        decay_factor = st.slider(
            "–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è –∏–µ—Ä–∞—Ä—Ö–∏–∏ (–¥–ª—è –∫–æ—Å–æ—É–≥–æ–ª—å–Ω–æ–≥–æ –±–∞–∑–∏—Å–∞)",
            min_value=0.0,
            max_value=1.0,
            value=float(st.session_state.get("ac_decay_factor", 0.5)),
            step=0.05,
            key="ac_decay_factor",
            help="–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è '–∫–æ—Å–æ—É–≥–æ–ª—å–Ω–æ–≥–æ –±–∞–∑–∏—Å–∞' (oblique).",
        )

    with col_params2:
        st.markdown("### üéØ –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±–∞–∑–∏—Å")

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–¥—ã 1-3 —É—Ä–æ–≤–Ω–µ–π (–º–∞–∫—Å–∏–º—É–º 2 —Ç–æ—á–∫–∏)
        codes = sorted(
            [c for c in classifier_labels.keys() if re.match(r"^[\d\.]+$", c) and c.count('.') <= 2],
            key=lambda x: (get_code_depth(x), x),
        )

        special_year = "–ì–æ–¥"
        node_options = [special_year, *codes]

        selected_nodes = st.multiselect(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª—ã –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è",
            options=node_options,
            default=[special_year],
            format_func=lambda x: x if x == special_year else _format_node_option(x, classifier_labels),
            key="ac_selected_nodes",
        )

        run_clicked = st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", type="primary", key="ac_run_btn")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ—Å—Ç–µ–π
    if run_clicked or st.session_state.get("ac_run_after_disambiguation", False):
        st.session_state["ac_run_after_disambiguation"] = False

        if st.session_state.get("ac_abort", False):
            st.error("‚ùå –ê–Ω–∞–ª–∏–∑ –æ—Ç–º–µ–Ω—ë–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
            st.session_state["ac_abort"] = False
            return

        initials_to_full = _build_initials_to_fullnames(df_lineage)
        ambiguous: Dict[str, List[str]] = {}

        for opt in selected_options:
            if options_meta.get(opt) == "initials_ambiguous":
                key = _canon_initials(opt)
                fulls = initials_to_full.get(key, [])
                resolved = st.session_state.get("ac_disambiguation", {}).get(key)
                if not resolved and len(fulls) > 1:
                    ambiguous[key] = fulls

        if ambiguous:
            _show_disambiguation_dialog(ambiguous)
            return

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã —Å—Ç–∞—Ç–µ–π..."):
            df_articles = load_articles_data()

        if df_articles is None or df_articles.empty:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å `articles_scores.csv`. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ–∞–π–ª –¥–æ—Å—Ç—É–ø–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏.")
            return

        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
        with st.spinner("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è..."):
            dataset = _build_articles_dataset(
                selected_options=selected_options,
                options_meta=options_meta,
                df_lineage=df_lineage,
                idx_lineage=idx_lineage,
                lineage_func=lineage_func,
                df_articles=df_articles,
                scope=scope,
            )

        if dataset.empty:
            st.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ç—å–∏ –Ω–∏ –ø–æ –æ–¥–Ω–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π —à–∫–æ–ª–µ/–∞–≤—Ç–æ—Ä—É.")
            return

        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
        school_counts = dataset["school"].value_counts().to_dict()
        non_empty_schools = [k for k, v in school_counts.items() if v > 0]

        if len(non_empty_schools) < 2:
            st.error(
                "‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: —Å—Ç–∞—Ç—å–∏ –Ω–∞–π–¥–µ–Ω—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–¥–Ω–æ–π —à–∫–æ–ª—ã/–∞–≤—Ç–æ—Ä–∞.\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–π –æ—Ö–≤–∞—Ç –∏–ª–∏ –¥—Ä—É–≥–æ–π –Ω–∞–±–æ—Ä —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π/–∞–≤—Ç–æ—Ä–æ–≤."
            )
            with st.expander("üîé –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: —Å–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π –ø–æ–ø–∞–ª–æ –≤ –∫–∞–∂–¥—É—é —à–∫–æ–ª—É", expanded=True):
                st.write(school_counts)
            return

        with st.expander("üîé –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: —Å–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π –ø–æ–ø–∞–ª–æ –≤ –∫–∞–∂–¥—É—é —à–∫–æ–ª—É", expanded=False):
            st.write(school_counts)

        # –ü—Ä–∏–∑–Ω–∞–∫–∏
        meta_cols = {"Article_id", "Authors", "Title", "Journal", "Volume", "Issue", "school", "Year", "Year_num"}
        all_cols = dataset.columns.tolist()
        classifier_cols = [c for c in all_cols if c not in meta_cols and re.match(r"^[\d\.]+$", str(c))]
        all_feature_cols = [*classifier_cols, "Year_num"]

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        if selected_nodes:
            feature_cols = _filter_feature_columns(all_feature_cols, selected_nodes)
        else:
            feature_cols = classifier_cols  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ–∑ –≥–æ–¥–∞

        # –ß–∏—Å—Ç–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        for col in feature_cols:
            dataset[col] = pd.to_numeric(dataset[col], errors="coerce").fillna(0)

        if not feature_cols:
            st.error("‚ùå –ù–µ –≤—ã–±—Ä–∞–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —É–∑–ª—ã/–≥–æ–¥).")
            return

        # –ê–Ω–∞–ª–∏–∑
        with st.spinner("–†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ (—Å–∏–ª—É—ç—Ç, DB, CH)..."):
            results = compute_article_analysis(
                df=dataset,
                feature_columns=feature_cols,
                metric=metric_choice,
                decay_factor=float(decay_factor),
            )

        if not results:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –ø—É—Å—Ç—ã–µ).")
            return

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")

        m1, m2, m3 = st.columns(3)
        with m1:
            st.metric("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∏–ª—É—ç—Ç–∞", f"{results.get('silhouette_avg', 0):.3f}")
            st.caption("–°—Ç–µ–ø–µ–Ω—å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π —à–∫–æ–ª/–∞–≤—Ç–æ—Ä–æ–≤ (–æ—Ç -1 –¥–æ 1).")
        with m2:
            db = results.get("davies_bouldin")
            st.metric("–ò–Ω–¥–µ–∫—Å –î—ç–≤–∏—Å–∞‚Äì–ë–æ—É–ª–¥–∏–Ω–∞", f"{db:.3f}" if isinstance(db, (float, int)) else "‚Äî")
            st.caption("–ú–µ–Ω—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–±—ã—á–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –±–æ–ª–µ–µ —á—ë—Ç–∫–æ–º—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é.")
        with m3:
            ch = results.get("calinski_harabasz")
            st.metric("–ò–Ω–¥–µ–∫—Å –ö–∞–ª–∏–Ω—Å–∫–æ–≥–æ‚Äì–•–∞—Ä–∞–±–∞–∑–∞", f"{int(ch)}" if isinstance(ch, (float, int)) else "‚Äî")
            st.caption("–ë–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–±—ã—á–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –±–æ–ª–µ–µ —á—ë—Ç–∫–æ–º—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é.")

        st.markdown("### üìà –ì—Ä–∞—Ñ–∏–∫ —Å–∏–ª—É—ç—Ç–∞")
        fig = create_articles_silhouette_plot(
            sample_scores=results["sample_silhouette_values"],
            labels=results["labels"],
            school_order=results["school_order"],
            overall_score=results["silhouette_avg"],
            metric_label=DISTANCE_METRIC_LABELS[metric_choice],
        )
        st.pyplot(fig)

        # –¶–µ–Ω—Ç—Ä–æ–∏–¥—ã
        school_order = results.get("school_order", [])
        centroids_dist = results.get("centroids_dist")

        if isinstance(school_order, list) and len(school_order) == 2 and isinstance(centroids_dist, (float, int)):
            st.info(f"**–ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º–∏ —à–∫–æ–ª:** {centroids_dist:.3f}")
        elif isinstance(school_order, list) and len(school_order) > 2 and centroids_dist is not None:
            with st.expander("–ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º–∏", expanded=False):
                dist_df = pd.DataFrame(centroids_dist, index=school_order, columns=school_order)
                st.dataframe(dist_df, use_container_width=True)

        st.markdown("### üìã –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        summary_df = create_comparison_summary(dataset, feature_cols)
        st.dataframe(summary_df, use_container_width=True, hide_index=True)

        with st.expander("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", expanded=False):
            _download_dataframe(summary_df, "articles_comparison_stats")

        with st.expander("üìÑ –°–ø–∏—Å–æ–∫ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π", expanded=False):
            view_cols = [c for c in ["Article_id", "school", "Authors", "Title", "Year"] if c in dataset.columns]
            view_df = dataset[view_cols].copy()
            rename = {"Article_id": "ID", "school": "–®–∫–æ–ª–∞/–ê–≤—Ç–æ—Ä", "Authors": "–ê–≤—Ç–æ—Ä—ã", "Title": "–ó–∞–≥–æ–ª–æ–≤–æ–∫", "Year": "–ì–æ–¥"}
            view_df = view_df.rename(columns=rename)
            st.dataframe(view_df, use_container_width=True, hide_index=True)

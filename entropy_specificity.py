"""
–ú–æ–¥—É–ª—å —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ä—ã –æ–±—â–Ω–æ—Å—Ç–∏/—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ—Å—Ç–∏ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π.

–†–µ–∞–ª–∏–∑—É–µ—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é —Ñ–æ—Ä–º—É–ª—É –®–µ–Ω–Ω–æ–Ω–∞ –∏ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–º
–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º Z –¥–ª—è —É—á–µ—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞.
"""

from __future__ import annotations

from typing import Dict, List, Optional, Tuple
import numpy as np
import pandas as pd


def get_code_depth(code: str) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª—É–±–∏–Ω—É (—É—Ä–æ–≤–µ–Ω—å) –∫–æ–¥–∞ –≤ –∏–µ—Ä–∞—Ä—Ö–∏–∏."""
    if not code:
        return 0
    return code.count(".") + 1


def get_parent_code(code: str) -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–¥ –∏–ª–∏ None –¥–ª—è –∫–æ—Ä–Ω–µ–≤—ã—Ö."""
    if "." not in code:
        return None
    return code.rsplit(".", 1)[0]


def get_ancestor_codes(code: str) -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–µ–¥–∫–æ–≤ –∫–æ–¥–∞ (–æ—Ç –∫–æ—Ä–Ω—è –∫ —Ç–µ–∫—É—â–µ–º—É, –∏—Å–∫–ª—é—á–∞—è —Å–∞–º –∫–æ–¥)."""
    ancestors = []
    current = get_parent_code(code)
    while current:
        ancestors.insert(0, current)
        current = get_parent_code(current)
    return ancestors


def count_children(code: str, all_codes: List[str]) -> int:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä—è–º—ã—Ö –ø–æ—Ç–æ–º–∫–æ–≤ –¥–∞–Ω–Ω–æ–≥–æ —É–∑–ª–∞.

    Args:
        code: –ö–æ–¥ —É–∑–ª–∞
        all_codes: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–¥–æ–≤ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä—è–º—ã—Ö –¥–æ—á–µ—Ä–Ω–∏—Ö —É–∑–ª–æ–≤
    """
    prefix = code + "."
    depth = get_code_depth(code)
    children = [
        c for c in all_codes 
        if c.startswith(prefix) and get_code_depth(c) == depth + 1
    ]
    return len(children)


def calculate_z_coefficient(
    code: str,
    all_codes: List[str]
) -> float:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç Z –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —É–∑–ª–∞.

    Z_i = –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –ø–æ ancestors(i) –æ—Ç 1/log(k_d),
    –≥–¥–µ k_d - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—á–µ—Ä–Ω–∏—Ö –≤–µ—Ç–≤–µ–π —É –ø—Ä–µ–¥–∫–∞ d.

    Args:
        code: –ö–æ–¥ —É–∑–ª–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        all_codes: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–¥–æ–≤ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ

    Returns:
        –ó–Ω–∞—á–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ Z
    """
    ancestors = get_ancestor_codes(code)

    if not ancestors:
        # –£–∑–µ–ª –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è - –Ω–µ—Ç –ø—Ä–µ–¥–∫–æ–≤
        return 1.0

    z = 1.0
    for ancestor in ancestors:
        k_d = count_children(ancestor, all_codes)
        if k_d > 1:
            # log —Å –æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º 2 –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π –º–µ—Ä—ã
            z *= 1.0 / np.log2(k_d)
        # –ï—Å–ª–∏ k_d <= 1, —Ç–æ 1/log(k_d) –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –∏–ª–∏ 1, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º

    return z


def calculate_entropy_shannon(
    profile: pd.Series,
    min_threshold: float = 0.0
) -> float:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é —ç–Ω—Ç—Ä–æ–ø–∏—é –®–µ–Ω–Ω–æ–Ω–∞.

    H = -—Å—É–º–º–∞ p_i * log(p_i)

    Args:
        profile: –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å (–±–∞–ª–ª—ã –ø–æ –∫–æ–¥–∞–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞)
        min_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ - –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∏–∂–µ –ø—Ä–∏–≤–æ–¥—è—Ç—Å—è –∫ –Ω—É–ª—é

    Returns:
        –ó–Ω–∞—á–µ–Ω–∏–µ —ç–Ω—Ç—Ä–æ–ø–∏–∏
    """
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
    values = profile.copy()
    values[values < min_threshold] = 0.0

    # –£–±–∏—Ä–∞–µ–º –Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    values = values[values > 0]

    if len(values) == 0:
        return 0.0

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞ —Å—É–º–º—É (–ø–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)
    total = values.sum()
    if total == 0:
        return 0.0

    probabilities = values / total

    # –í—ã—á–∏—Å–ª—è–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é
    entropy = -np.sum(probabilities * np.log2(probabilities))

    return entropy


def calculate_entropy_hierarchical(
    profile: pd.Series,
    all_codes: List[str],
    min_threshold: float = 0.0
) -> float:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é —ç–Ω—Ç—Ä–æ–ø–∏—é —Å —É—á–µ—Ç–æ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ Z.

    H = -—Å—É–º–º–∞ Z_i * p_i * log(p_i)

    Args:
        profile: –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å (–±–∞–ª–ª—ã –ø–æ –∫–æ–¥–∞–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞)
        all_codes: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–¥–æ–≤ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ
        min_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ - –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∏–∂–µ –ø—Ä–∏–≤–æ–¥—è—Ç—Å—è –∫ –Ω—É–ª—é

    Returns:
        –ó–Ω–∞—á–µ–Ω–∏–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —ç–Ω—Ç—Ä–æ–ø–∏–∏
    """
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
    values = profile.copy()
    values[values < min_threshold] = 0.0

    # –£–±–∏—Ä–∞–µ–º –Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    values = values[values > 0]

    if len(values) == 0:
        return 0.0

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞ —Å—É–º–º—É (–ø–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)
    total = values.sum()
    if total == 0:
        return 0.0

    probabilities = values / total

    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã Z –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–¥–∞
    z_coefficients = {}
    for code in probabilities.index:
        z_coefficients[code] = calculate_z_coefficient(code, all_codes)

    # –í—ã—á–∏—Å–ª—è–µ–º –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é —ç–Ω—Ç—Ä–æ–ø–∏—é
    entropy = 0.0
    for code, p_i in probabilities.items():
        z_i = z_coefficients.get(code, 1.0)
        entropy -= z_i * p_i * np.log2(p_i)

    return entropy


def search_by_entropy(
    scores_df: pd.DataFrame,
    feature_columns: List[str],
    use_hierarchical: bool = False,
    min_threshold: float = 3.0,
    ascending: bool = True
) -> pd.DataFrame:
    """
    –ò—â–µ—Ç –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏–∏ –ø–æ –º–µ—Ä–µ –æ–±—â–Ω–æ—Å—Ç–∏/—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ—Å—Ç–∏ (—ç–Ω—Ç—Ä–æ–ø–∏—è).

    Args:
        scores_df: DataFrame —Å —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø—Ä–æ—Ñ–∏–ª—è–º–∏
        feature_columns: –°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–∫–æ–¥—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞)
        use_hierarchical: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç Z
        min_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –æ—Ç—Å–µ—á–µ–Ω–∏—è –º–∞–ª—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        ascending: True - –æ—Ç –Ω–∏–∑–∫–æ–π —ç–Ω—Ç—Ä–æ–ø–∏–∏ –∫ –≤—ã—Å–æ–∫–æ–π (—É–∑–∫–∏–µ ‚Üí —à–∏—Ä–æ–∫–∏–µ —Ç–µ–º—ã),
                   False - –Ω–∞–æ–±–æ—Ä–æ—Ç

    Returns:
        DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ —ç–Ω—Ç—Ä–æ–ø–∏–∏
    """
    if scores_df.empty:
        return scores_df

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
    available_cols = [c for c in feature_columns if c in scores_df.columns]
    if not available_cols:
        raise ValueError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

    # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    result_df = scores_df.copy()

    # –í—ã—á–∏—Å–ª—è–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
    entropies = []
    for idx, row in result_df.iterrows():
        profile = row[available_cols]

        if use_hierarchical:
            entropy = calculate_entropy_hierarchical(
                profile, 
                available_cols, 
                min_threshold
            )
        else:
            entropy = calculate_entropy_shannon(
                profile, 
                min_threshold
            )

        entropies.append(entropy)

    # –î–æ–±–∞–≤–ª—è–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result_df["entropy"] = entropies

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–Ω—É–ª–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ø–æ—Å–ª–µ –ø–æ—Ä–æ–≥–∞)
    def count_nonzero_after_threshold(row):
        vals = row[available_cols]
        return (vals >= min_threshold).sum()

    result_df["features_count"] = result_df.apply(
        count_nonzero_after_threshold, 
        axis=1
    )

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —ç–Ω—Ç—Ä–æ–ø–∏–∏
    result_df = result_df.sort_values("entropy", ascending=ascending)

    return result_df


def interpret_entropy(
    entropy: float,
    use_hierarchical: bool = False
) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –∑–Ω–∞—á–µ–Ω–∏—è —ç–Ω—Ç—Ä–æ–ø–∏–∏.

    Args:
        entropy: –ó–Ω–∞—á–µ–Ω–∏–µ —ç–Ω—Ç—Ä–æ–ø–∏–∏
        use_hierarchical: –ë—ã–ª–∞ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º Z

    Returns:
        –¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
    """
    if entropy < 1.0:
        return "üîπ –û—á–µ–Ω—å —É–∑–∫–∞—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ‚Äî –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–µ–º–µ"
    elif entropy < 2.5:
        return "üî∏ –£–∑–∫–∞—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ‚Äî —Ç–µ–º–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞"
    elif entropy < 4.0:
        return "üü° –£–º–µ—Ä–µ–Ω–Ω–∞—è —à–∏—Ä–æ—Ç–∞ ‚Äî –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–º–µ–∂–Ω—ã—Ö —Ç–µ–º"
    elif entropy < 5.5:
        return "üü† –®–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç ‚Äî –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ç–µ–º"
    else:
        return "üî¥ –û—á–µ–Ω—å —à–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç ‚Äî –º–µ–∂–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å –≤—ã—Å–æ–∫–æ–π —Å—Ç–µ–ø–µ–Ω—å—é –æ–±–æ–±—â–µ–Ω–∏—è"

# articles_comparison.py
"""
–ú–æ–¥—É–ª—å —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª –ø–æ –ø—É–±–ª–∏–∫–∞—Ü–∏—è–º (—Å—Ç–∞—Ç—å—è–º).
–†–µ–∞–ª–∏–∑—É–µ—Ç –ª–æ–≥–∏–∫—É, –∞–Ω–∞–ª–æ–≥–∏—á–Ω—É—é school_comparison, –Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç–∞—Ç–µ–π.

–û–ë–ù–û–í–õ–ï–ù–ò–Ø:
- –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å—Ç–∞—Ç–µ–π –∏–∑ articles_classifier.json
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≤—Å–µ—Ö —É—Ä–æ–≤–Ω–µ–π –∏–µ—Ä–∞—Ä—Ö–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
"""

from __future__ import annotations

import json
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from typing import List, Set, Dict, Tuple, Optional, Callable, Any, Literal

from sklearn.metrics import (
    silhouette_samples,
    silhouette_score,
    davies_bouldin_score,
    calinski_harabasz_score
)
from sklearn.metrics.pairwise import euclidean_distances, cosine_distances
from scipy.spatial.distance import cdist

# ==============================================================================
# –ö–û–ù–°–¢–ê–ù–¢–´ –ò –¢–ò–ü–´
# ==============================================================================

POSSIBLE_PATHS = [
    "articles_scores.csv",
    "articles_scores/articles_scores.csv",
    "db_articles/articles_scores.csv"
]

METADATA_COLS = {
    "Article_id", "Authors", "Title", "Journal",
    "Volume", "Issue", "school", "Year", "Year_num"
}

DistanceMetric = Literal[
    "euclidean_orthogonal",
    "cosine_orthogonal",
    "euclidean_oblique",
    "cosine_oblique"
]

DISTANCE_METRIC_LABELS: Dict[DistanceMetric, str] = {
    "euclidean_orthogonal": "–ï–≤–∫–ª–∏–¥–æ–≤–æ (–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π –±–∞–∑–∏—Å)",
    "cosine_orthogonal": "–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ (–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π –±–∞–∑–∏—Å)",
    "euclidean_oblique": "–ï–≤–∫–ª–∏–¥–æ–≤–æ (–∫–æ—Å–æ—É–≥–æ–ª—å–Ω—ã–π –±–∞–∑–∏—Å)",
    "cosine_oblique": "–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ (–∫–æ—Å–æ—É–≥–æ–ª—å–Ω—ã–π –±–∞–∑–∏—Å)",
}

SILHOUETTE_COLORS = ["#FF8C42", "#FFD166", "#F77F00", "#FCBF49", "#EF476F", "#06D6A0", "#118AB2", "#073B4C"]

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –î–õ–Ø –°–¢–ê–¢–ï–ô
CLASSIFIER_PATHS = [
    "articles_classifier.json",
    "db_articles/articles_classifier.json",
]

ARTICLES_HELP_TEXT = """
### üî¨ –ê–Ω–∞–ª–∏–∑ –ø—É–±–ª–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª

–≠—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å—Ä–∞–≤–Ω–∏—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ñ–∏–ª–∏ —Å—Ç–∞—Ç–µ–π,
–Ω–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—è–º–∏ —Ä–∞–∑–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª.

**–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**

1. **–í—ã–±–æ—Ä –æ—Ö–≤–∞—Ç–∞**: –ú–æ–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä—è–º—ã—Ö —É—á–µ–Ω–∏–∫–æ–≤ –∏–ª–∏ –≤—Å—é —à–∫–æ–ª—É —Ü–µ–ª–∏–∫–æ–º.

2. **–ì–∏–±–∫–∏–π –±–∞–∑–∏—Å**: 
   - **–í–µ—Å—å –±–∞–∑–∏—Å** ‚Äî –∞–Ω–∞–ª–∏–∑ –ø–æ –≤—Å–µ–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∫–æ–¥–∞–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
   - **–û—Ç–¥–µ–ª—å–Ω—ã–µ —É–∑–ª—ã** ‚Äî –≤—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ (–ø—Ä–∏ –≤—ã–±–æ—Ä–µ —É–∑–ª–∞ –≤–∫–ª—é—á–∞—é—Ç—Å—è –≤—Å–µ –µ–≥–æ –ø–æ–¥—É–∑–ª—ã)
   - **–ì–æ–¥** ‚Äî –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–∫—Ç–æ—Ä–∞

3. **–ú–µ—Ç—Ä–∏–∫–∏**:
   - *–ü—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π –±–∞–∑–∏—Å*: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ, –≥–¥–µ –≤—Å–µ —Ç–µ–º—ã —Ä–∞–≤–Ω–æ–ø—Ä–∞–≤–Ω—ã.
   - *–ö–æ—Å–æ—É–≥–æ–ª—å–Ω—ã–π –±–∞–∑–∏—Å*: –£—á–∏—Ç—ã–≤–∞–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—é —Ç–µ–º –¥–ª—è –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.

**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫:**

- **–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∏–ª—É—ç—Ç–∞**: –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–µ–ø–µ–Ω—å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤. –ß–µ–º –≤—ã—à–µ, —Ç–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–µ–µ –ø—Ä–æ—Ñ–∏–ª—å —à–∫–æ–ª—ã.
- **–ò–Ω–¥–µ–∫—Å –î—ç–≤–∏—Å–∞‚Äì–ë–æ—É–ª–¥–∏–Ω–∞**: –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–º–µ–Ω—å—à–µ ‚Äî –ª—É—á—à–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ).
- **–ò–Ω–¥–µ–∫—Å –ö–∞–ª–∏–Ω—Å–∫–æ–≥–æ‚Äì–•–∞—Ä–∞–±–∞–∑–∞**: –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –¥–∏—Å–ø–µ—Ä—Å–∏—é (–±–æ–ª—å—à–µ ‚Äî –ª—É—á—à–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã –∫–ª–∞—Å—Ç–µ—Ä—ã).
"""

CLASSIFIER_LIST_TEXT = """
–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ `articles_classifier.json`.
"""

# ==============================================================================
# –ó–ê–ì–†–£–ó–ö–ê –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê
# ==============================================================================

def load_articles_classifier() -> Dict[str, str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç–∞—Ç–µ–π –∏–∑ JSON —Ñ–∞–π–ª–∞."""
    for path_str in CLASSIFIER_PATHS:
        path = Path(path_str)
        if path.exists():
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –∏–∑ {path}: {e}")
                continue
    print("‚ö†Ô∏è –§–∞–π–ª articles_classifier.json –Ω–µ –Ω–∞–π–¥–µ–Ω, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –±—É–¥–µ—Ç –ø—É—Å—Ç—ã–º")
    return {}

# ==============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò (–ò–ï–†–ê–†–•–ò–Ø)
# ==============================================================================

def get_code_depth(code: str) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª—É–±–∏–Ω—É (—É—Ä–æ–≤–µ–Ω—å) –∫–æ–¥–∞ –≤ –∏–µ—Ä–∞—Ä—Ö–∏–∏ (1.1 -> 2, 1.1.1 -> 3)."""
    if not code or code == "Year":
        return 0
    return code.count(".") + 1

def get_parent_code(code: str) -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–¥."""
    if "." not in code:
        return None
    return code.rsplit(".", 1)[0]

def get_ancestor_codes(code: str) -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–µ–¥–∫–æ–≤ –∫–æ–¥–∞."""
    ancestors = []
    current = code
    while current:
        ancestors.insert(0, current)
        current = get_parent_code(current)
    return ancestors

def is_descendant_of(code: str, ancestor: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ code –ø–æ—Ç–æ–º–∫–æ–º ancestor."""
    if code == ancestor:
        return True
    return code.startswith(ancestor + ".")

# ==============================================================================
# –ú–ê–¢–ï–ú–ê–¢–ò–ö–ê (–ö–û–°–û–£–ì–û–õ–¨–ù–´–ô –ë–ê–ó–ò–° –ò –†–ê–°–°–¢–û–Ø–ù–ò–Ø)
# ==============================================================================

def build_oblique_transform_matrix(feature_columns: List[str], decay_factor: float = 0.5) -> np.ndarray:
    """–°—Ç—Ä–æ–∏—Ç –º–∞—Ç—Ä–∏—Ü—É —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —É—á–µ—Ç–∞ –∏–µ—Ä–∞—Ä—Ö–∏–∏."""
    n = len(feature_columns)
    col_to_idx = {col: i for i, col in enumerate(feature_columns)}
    transform = np.eye(n)

    for i, col in enumerate(feature_columns):
        if col == "Year_num":
            continue
        ancestors = get_ancestor_codes(col)
        for depth, ancestor in enumerate(ancestors[:-1]):
            if ancestor in col_to_idx:
                j = col_to_idx[ancestor]
                distance = len(ancestors) - depth - 1
                weight = decay_factor ** distance
                transform[i, j] = weight

    return transform

def apply_oblique_transform(data: np.ndarray, feature_columns: List[str], decay_factor: float = 0.5) -> np.ndarray:
    transform = build_oblique_transform_matrix(feature_columns, decay_factor)
    return data @ transform.T

def compute_distance_matrix(data: np.ndarray, feature_columns: List[str], metric: DistanceMetric, decay_factor: float = 0.5) -> np.ndarray:
    """–í—ã—á–∏—Å–ª—è–µ—Ç –º–∞—Ç—Ä–∏—Ü—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π —Å–æ–≥–ª–∞—Å–Ω–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ."""
    if metric in ("euclidean_oblique", "cosine_oblique"):
        data_transformed = apply_oblique_transform(data, feature_columns, decay_factor)
    else:
        data_transformed = data

    if "euclidean" in metric:
        return euclidean_distances(data_transformed)
    else:
        return cosine_distances(data_transformed)

# ==============================================================================
# –†–ê–ë–û–¢–ê –° –î–ê–ù–ù–´–ú–ò –°–¢–ê–¢–ï–ô
# ==============================================================================

def to_short_name(full_name: str) -> str:
    """'–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á' -> '–ò–≤–∞–Ω–æ–≤ –ò.–ò.'"""
    parts = full_name.strip().replace('.', ' ').split()
    if not parts:
        return ""
    surname = parts[0]
    initials = ""
    if len(parts) > 1:
        initials += parts[1][0] + "."
    if len(parts) > 2:
        initials += parts[2][0] + "."
    return f"{surname} {initials}"

def canonicalize_author_name(name: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏–º—è –∞–≤—Ç–æ—Ä–∞ –∫ –µ–¥–∏–Ω–æ–º—É –≤–∏–¥—É: '–∏–≤–∞–Ω–æ–≤ –∏.–∏.'"""
    if not isinstance(name, str):
        return ""
    s = name.strip().lower()
    if not s:
        return ""

    s = s.replace("—ë", "–µ")
    s = s.replace(",", " ")
    s = re.sub(r"\s+", " ", s).strip()

    compact = re.sub(r"\s+", "", s)

    m = re.search(r"[a-z–∞-—è]\.", compact)
    if m:
        pos = m.start()
        surname = compact[:pos]
        initials_raw = compact[pos:]
    else:
        letters = re.findall(r"[a-z–∞-—è]", compact)
        if len(letters) < 2:
            return ""
        surname = compact[:-2]
        initials_raw = compact[-2:]

    surname = re.sub(r"[^a-z–∞-—è\-]", "", surname)
    if not surname:
        return ""

    init_letters = re.findall(r"[a-z–∞-—è]", initials_raw)
    if not init_letters:
        return ""

    initials = "".join(ch + "." for ch in init_letters[:3])
    return f"{surname} {initials}"

def normalize_authors_set(authors_str: str) -> Set[str]:
    """'–ò–≤–∞–Ω–æ–≤ –ò.–ò.; –ü–µ—Ç—Ä–æ–≤ –ü.–ü.' -> {'–∏–≤–∞–Ω–æ–≤ –∏.–∏.', '–ø–µ—Ç—Ä–æ–≤ –ø.–ø.'}"""
    if not isinstance(authors_str, str):
        return set()
    raw_names = re.split(r"[;]", authors_str)
    res: Set[str] = set()
    for n in raw_names:
        canon = canonicalize_author_name(n)
        if canon:
            res.add(canon)
    return res

def load_articles_data() -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV —Å–æ —Å—Ç–∞—Ç—å—è–º–∏."""
    for path_str in POSSIBLE_PATHS:
        path = Path(path_str)
        if path.exists():
            try:
                df = pd.read_csv(path, sep=';', dtype={'Year': str, 'Article_id': str})
                if df.shape[1] < 2:
                    df = pd.read_csv(path, sep=',', dtype={'Year': str, 'Article_id': str})
                return df
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {path}: {e}")
                continue
    return pd.DataFrame()

# ==============================================================================
# –ê–ù–ê–õ–ò–ó (–í–´–ß–ò–°–õ–ï–ù–ò–Ø)
# ==============================================================================

def compute_article_analysis(
    df: pd.DataFrame,
    feature_columns: List[str],
    metric: DistanceMetric,
    decay_factor: float = 0.5
) -> Dict[str, Any]:
    """
    –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞: –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –∏ –º–µ—Ç—Ä–∏–∫.
    """
    if df.empty or not feature_columns:
        return {}

    X = df[feature_columns].values
    labels = df["school"].astype(str).values
    unique_labels = np.unique(labels)
    school_order = list(unique_labels)

    if len(unique_labels) < 2 or X.shape[0] < 2:
        return {
            "silhouette_avg": 0.0,
            "sample_silhouette_values": np.zeros(X.shape[0]),
            "labels": labels,
            "school_order": school_order,
            "unique_schools": school_order,
            "davies_bouldin": None,
            "calinski_harabasz": None,
            "centroids_dist": None
        }

    dist_matrix = compute_distance_matrix(X, feature_columns, metric, decay_factor)

    try:
        silhouette_avg = silhouette_score(dist_matrix, labels, metric="precomputed")
        sample_silhouette_values = silhouette_samples(dist_matrix, labels, metric="precomputed")
    except Exception:
        silhouette_avg = 0.0
        sample_silhouette_values = np.zeros(X.shape[0])

    if "oblique" in metric:
        X_for_metrics = apply_oblique_transform(X, feature_columns, decay_factor)
    else:
        X_for_metrics = X

    try:
        db_score = davies_bouldin_score(X_for_metrics, labels)
    except Exception:
        db_score = None

    try:
        ch_score = calinski_harabasz_score(X_for_metrics, labels)
    except Exception:
        ch_score = None

    try:
        centroids = [X_for_metrics[labels == lab].mean(axis=0) for lab in unique_labels]
        centroid_dist_matrix = cdist(centroids, centroids, metric="euclidean")
        dist_info = centroid_dist_matrix[0, 1] if len(unique_labels) == 2 else centroid_dist_matrix
    except Exception:
        dist_info = None

    return {
        "silhouette_avg": float(silhouette_avg),
        "sample_silhouette_values": sample_silhouette_values,
        "labels": labels,
        "school_order": school_order,
        "unique_schools": school_order,
        "davies_bouldin": db_score,
        "calinski_harabasz": ch_score,
        "centroids_dist": dist_info
    }

def create_comparison_summary(df: pd.DataFrame, feature_cols: List[str]) -> pd.DataFrame:
    """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –ø–æ —à–∫–æ–ª–∞–º."""
    summary_data: List[Dict[str, Any]] = []
    unique_schools = df["school"].unique()
    thematic_cols = [c for c in feature_cols if c != "Year_num"]
    has_year = "Year_num" in feature_cols and "Year_num" in df.columns

    for school in unique_schools:
        sub = df[df["school"] == school]
        num_data = sub[thematic_cols] if thematic_cols else pd.DataFrame(index=sub.index)

        row: Dict[str, Any] = {
            "–ù–∞—É—á–Ω–∞—è —à–∫–æ–ª–∞": school,
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π": int(len(sub)),
        }

        if len(thematic_cols) > 0:
            profile_sum = num_data.sum(axis=1)
            row.update({
                "–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ –ø—Ä–æ—Ñ–∏–ª—è": float(profile_sum.mean()),
                "–°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ": float(profile_sum.std(ddof=1)) if len(profile_sum) > 1 else 0.0,
                "–û—Ö–≤–∞—Ç —Ç–µ–º (—Å—Ä–µ–¥–Ω–µ–µ)": float((num_data > 0).sum(axis=1).mean()),
            })
        else:
            row.update({
                "–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ –ø—Ä–æ—Ñ–∏–ª—è": 0.0,
                "–°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ": 0.0,
                "–û—Ö–≤–∞—Ç —Ç–µ–º (—Å—Ä–µ–¥–Ω–µ–µ)": 0.0,
            })

        if has_year:
            years = sub["Year_num"].dropna()
            if len(years) > 0:
                row["–°—Ä–µ–¥–Ω–∏–π –≥–æ–¥"] = float(years.mean())
                row["–î–∏–∞–ø–∞–∑–æ–Ω –≥–æ–¥–æ–≤"] = f"{int(years.min())}‚Äì{int(years.max())}"
            else:
                row["–°—Ä–µ–¥–Ω–∏–π –≥–æ–¥"] = np.nan
                row["–î–∏–∞–ø–∞–∑–æ–Ω –≥–æ–¥–æ–≤"] = ""

        summary_data.append(row)

    return pd.DataFrame(summary_data)

def create_articles_silhouette_plot(
    sample_scores: np.ndarray,
    labels: np.ndarray,
    school_order: List[str],
    overall_score: float,
    metric_label: str
) -> plt.Figure:
    """–û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç —Å–∏–ª—É—ç—Ç–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫."""
    n_schools = len(school_order)
    fig, ax = plt.subplots(figsize=(10, max(6, n_schools * 1.5)))
    y_lower = 10

    colors = SILHOUETTE_COLORS[:n_schools] if n_schools <= len(SILHOUETTE_COLORS) else \
        (SILHOUETTE_COLORS * ((n_schools // len(SILHOUETTE_COLORS)) + 1))[:n_schools]

    label_to_idx = {name: i for i, name in enumerate(school_order)}
    numeric_labels = np.array([label_to_idx[l] for l in labels])

    for idx, school in enumerate(school_order):
        mask = numeric_labels == idx
        cluster_scores = sample_scores[mask]
        if cluster_scores.size == 0:
            continue
        cluster_scores = np.sort(cluster_scores)
        size = cluster_scores.size
        y_upper = y_lower + size
        color = colors[idx]

        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_scores,
                        facecolor=color, edgecolor=color, alpha=0.85)
        ax.text(-0.05, y_lower + size / 2, f"{school} (n={size})",
               va="center", ha="right", fontsize=10, fontweight='bold')
        y_lower = y_upper + 10

    ax.axvline(x=overall_score, color="#2D3436", linestyle="--", linewidth=2,
              label=f"–°—Ä–µ–¥–Ω–∏–π —Å–∏–ª—É—ç—Ç: {overall_score:.3f}")
    ax.set_xlim([-1, 1])
    ax.set_xlabel("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∏–ª—É—ç—Ç–∞")
    ax.set_title(f"–ê–Ω–∞–ª–∏–∑ –ø—É–±–ª–∏–∫–∞—Ü–∏–π –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª\n{metric_label}", fontsize=14)
    ax.set_yticks([])
    ax.legend(loc="lower right")
    ax.grid(axis="x", linestyle=":", alpha=0.5)

    ax.axvspan(-1, -0.25, alpha=0.05, color="red")
    ax.axvspan(0.5, 1, alpha=0.05, color="green")

    fig.tight_layout()
    return fig

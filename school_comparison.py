"""
–ú–æ–¥—É–ª—å —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª –ø–æ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø—Ä–æ—Ñ–∏–ª—è–º.
–û—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∏–ª—É—ç—Ç–∞ (Silhouette Score).
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import Callable, Dict, List, Literal, Optional, Tuple, Set

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_samples, silhouette_score
from sklearn.metrics.pairwise import euclidean_distances, cosine_distances


# ==============================================================================
# –¢–ò–ü–´ –ò –ö–û–ù–°–¢–ê–ù–¢–´
# ==============================================================================

DistanceMetric = Literal[
    "euclidean_orthogonal",      # –ï–≤–∫–ª–∏–¥–æ–≤–æ –≤ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ–º –±–∞–∑–∏—Å–µ
    "cosine_orthogonal",         # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ –≤ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ–º –±–∞–∑–∏—Å–µ
    "euclidean_oblique",         # –ï–≤–∫–ª–∏–¥–æ–≤–æ –≤ –∫–æ—Å–æ—É–≥–æ–ª—å–Ω–æ–º –±–∞–∑–∏—Å–µ
    "cosine_oblique"             # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ –≤ –∫–æ—Å–æ—É–≥–æ–ª—å–Ω–æ–º –±–∞–∑–∏—Å–µ
]

ComparisonScope = Literal["direct", "all"]

DISTANCE_METRIC_LABELS: Dict[DistanceMetric, str] = {
    "euclidean_orthogonal": "–ï–≤–∫–ª–∏–¥–æ–≤–æ (–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π –±–∞–∑–∏—Å)",
    "cosine_orthogonal": "–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ (–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π –±–∞–∑–∏—Å)",
    "euclidean_oblique": "–ï–≤–∫–ª–∏–¥–æ–≤–æ (–∫–æ—Å–æ—É–≥–æ–ª—å–Ω—ã–π –±–∞–∑–∏—Å)",
    "cosine_oblique": "–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ (–∫–æ—Å–æ—É–≥–æ–ª—å–Ω—ã–π –±–∞–∑–∏—Å)",
}

SCOPE_LABELS: Dict[ComparisonScope, str] = {
    "direct": "–¢–æ–ª—å–∫–æ –ø—Ä—è–º—ã–µ –¥–∏—Å—Å–µ—Ä—Ç–∞–Ω—Ç—ã",
    "all": "–í—Å–µ –ø–æ–∫–æ–ª–µ–Ω–∏—è –¥–∏—Å—Å–µ—Ä—Ç–∞–Ω—Ç–æ–≤",
}


# ==============================================================================
# –†–ê–ë–û–¢–ê –° –ò–ï–†–ê–†–•–ò–ï–ô –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê
# ==============================================================================

def get_code_depth(code: str) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª—É–±–∏–Ω—É (—É—Ä–æ–≤–µ–Ω—å) –∫–æ–¥–∞ –≤ –∏–µ—Ä–∞—Ä—Ö–∏–∏."""
    if not code:
        return 0
    return code.count(".") + 1


def get_parent_code(code: str) -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–¥ –∏–ª–∏ None –¥–ª—è –∫–æ—Ä–Ω–µ–≤—ã—Ö."""
    if "." not in code:
        return None
    return code.rsplit(".", 1)[0]


def get_ancestor_codes(code: str) -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–µ–¥–∫–æ–≤ –∫–æ–¥–∞ (–æ—Ç –∫–æ—Ä–Ω—è –∫ —Ç–µ–∫—É—â–µ–º—É)."""
    ancestors = []
    current = code
    while current:
        ancestors.insert(0, current)
        current = get_parent_code(current)
    return ancestors


def is_descendant_of(code: str, ancestor: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ code –ø–æ—Ç–æ–º–∫–æ–º ancestor.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ code == ancestor –∏–ª–∏ code –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å ancestor.
    """
    if code == ancestor:
        return True
    return code.startswith(ancestor + ".")


def filter_columns_by_nodes(
    columns: List[str],
    selected_nodes: Optional[List[str]] = None
) -> List[str]:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —É–∑–ª–∞–º.

    –ï—Å–ª–∏ selected_nodes is None ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ (–≤–µ—Å—å –±–∞–∑–∏—Å).
    –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã —É–∑–ª—ã ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç—Ç–∏ —É–∑–ª—ã –∏ –í–°–ï –∏—Ö –ø–æ—Ç–æ–º–∫–∏ –Ω–∞ –ª—é–±–æ–π –≥–ª—É–±–∏–Ω–µ.

    Args:
        columns: –°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ (–∫–æ–¥–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞)
        selected_nodes: –°–ø–∏—Å–æ–∫ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤ (–∫–æ—Ä–Ω–µ–π –ø–æ–¥–¥–µ—Ä–µ–≤—å–µ–≤)

    Returns:
        –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫

    –ü—Ä–∏–º–µ—Ä—ã:
        - selected_nodes=None -> –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏
        - selected_nodes=["1.1"] -> 1.1, 1.1.1, 1.1.1.1, 1.1.1.2, 1.1.1.2.1, ...
        - selected_nodes=["1.1", "2.2"] -> –≤—Å–µ –ø–æ–¥ 1.1 + –≤—Å–µ –ø–æ–¥ 2.2
    """
    if selected_nodes is None or len(selected_nodes) == 0:
        # –í–µ—Å—å –±–∞–∑–∏—Å ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏
        return columns

    # –§–∏–ª—å—Ç—Ä—É–µ–º: –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è –ø–æ—Ç–æ–º–∫–∞–º–∏ –ª—é–±–æ–≥–æ –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤
    filtered = []
    for col in columns:
        for node in selected_nodes:
            if is_descendant_of(col, node):
                filtered.append(col)
                break  # –ù–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ —É–∑–ª—ã –¥–ª—è —ç—Ç–æ–π –∫–æ–ª–æ–Ω–∫–∏

    return filtered


def get_nodes_at_level(columns: List[str], level: int) -> List[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–∑–ª—ã —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è.

    Args:
        columns: –í—Å–µ –∫–æ–ª–æ–Ω–∫–∏
        level: –£—Ä–æ–≤–µ–Ω—å (1, 2, 3, ...)

    Returns:
        –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —É–∑–ª–æ–≤ –¥–∞–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
    """
    return sorted(set(col for col in columns if get_code_depth(col) == level))


def get_selectable_nodes(columns: List[str], max_level: int = 3) -> List[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–∑–ª—ã, –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–ª—è –≤—ã–±–æ—Ä–∞ (—É—Ä–æ–≤–Ω–∏ 1, 2, 3).
    –£–∑–ª—ã –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏—Ö —É—Ä–æ–≤–Ω–µ–π –Ω–µ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç—Å—è –¥–ª—è –≤—ã–±–æ—Ä–∞,
    —Ç–∞–∫ –∫–∞–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –Ω–∏–º –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º —É–∑–∫–∏–º.

    Args:
        columns: –í—Å–µ –∫–æ–ª–æ–Ω–∫–∏
        max_level: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —É–∑–ª–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3)

    Returns:
        –°–ø–∏—Å–æ–∫ —É–∑–ª–æ–≤ —É—Ä–æ–≤–Ω–µ–π 1..max_level
    """
    result = []
    for level in range(1, max_level + 1):
        result.extend(get_nodes_at_level(columns, level))
    return sorted(result)


# ==============================================================================
# –ü–û–°–¢–†–û–ï–ù–ò–ï –ú–ê–¢–†–ò–¶–´ –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ò –î–õ–Ø –ö–û–°–û–£–ì–û–õ–¨–ù–û–ì–û –ë–ê–ó–ò–°–ê
# ==============================================================================

def build_oblique_transform_matrix(
    feature_columns: List[str],
    decay_factor: float = 0.5
) -> np.ndarray:
    """
    –°—Ç—Ä–æ–∏—Ç –º–∞—Ç—Ä–∏—Ü—É —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∫–æ—Å–æ—É–≥–æ–ª—å–Ω–æ–≥–æ –±–∞–∑–∏—Å–∞.

    –ò–¥–µ—è –∫–æ—Å–æ—É–≥–æ–ª—å–Ω–æ–≥–æ –±–∞–∑–∏—Å–∞: –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ—á–µ—Ä–Ω–∏—Ö —É–∑–ª–æ–≤ —á–∞—Å—Ç–∏—á–Ω–æ 
    –Ω–∞—Å–ª–µ–¥—É—é—Ç—Å—è –æ—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö, —á—Ç–æ —É—á–∏—Ç—ã–≤–∞–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é 
    —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞.

    Args:
        feature_columns: –°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ (–∫–æ–¥–æ–≤)
        decay_factor: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –∫ –ø–æ—Ç–æ–º–∫–∞–º (0-1)

    Returns:
        –ú–∞—Ç—Ä–∏—Ü–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—Ä–∞ (n_features, n_features)
    """
    n = len(feature_columns)
    col_to_idx = {col: i for i, col in enumerate(feature_columns)}

    # –ù–∞—á–∏–Ω–∞–µ–º —Å –µ–¥–∏–Ω–∏—á–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
    transform = np.eye(n)

    for i, col in enumerate(feature_columns):
        ancestors = get_ancestor_codes(col)
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–ª–∏—è–Ω–∏–µ –ø—Ä–µ–¥–∫–æ–≤ —Å –∑–∞—Ç—É—Ö–∞–Ω–∏–µ–º
        for depth, ancestor in enumerate(ancestors[:-1]):  # –∏—Å–∫–ª—é—á–∞–µ–º —Å–∞–º —É–∑–µ–ª
            if ancestor in col_to_idx:
                j = col_to_idx[ancestor]
                # –ß–µ–º –¥–∞–ª—å—à–µ –ø—Ä–µ–¥–æ–∫, —Ç–µ–º –º–µ–Ω—å—à–µ –≤–ª–∏—è–Ω–∏–µ
                distance = len(ancestors) - depth - 1
                weight = decay_factor ** distance
                transform[i, j] = weight

    return transform


def apply_oblique_transform(
    data: np.ndarray,
    feature_columns: List[str],
    decay_factor: float = 0.5
) -> np.ndarray:
    """
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –∫–æ—Å–æ—É–≥–æ–ª—å–Ω–æ–≥–æ –±–∞–∑–∏—Å–∞ –∫ –¥–∞–Ω–Ω—ã–º.

    Args:
        data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (n_samples, n_features)
        feature_columns: –°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
        decay_factor: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è

    Returns:
        –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    transform = build_oblique_transform_matrix(feature_columns, decay_factor)
    return data @ transform.T


# ==============================================================================
# –í–´–ß–ò–°–õ–ï–ù–ò–ï –†–ê–°–°–¢–û–Ø–ù–ò–ô
# ==============================================================================

def compute_distance_matrix(
    data: np.ndarray,
    feature_columns: List[str],
    metric: DistanceMetric,
    decay_factor: float = 0.5
) -> np.ndarray:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –º–∞—Ç—Ä–∏—Ü—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –º–µ–∂–¥—É –æ–±—Ä–∞–∑—Ü–∞–º–∏.

    Args:
        data: –î–∞–Ω–Ω—ã–µ (n_samples, n_features)
        feature_columns: –°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
        metric: –¢–∏–ø –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        decay_factor: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è –¥–ª—è –∫–æ—Å–æ—É–≥–æ–ª—å–Ω–æ–≥–æ –±–∞–∑–∏—Å–∞

    Returns:
        –ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π (n_samples, n_samples)
    """
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∫–æ—Å–æ—É–≥–æ–ª—å–Ω–æ–≥–æ –±–∞–∑–∏—Å–∞
    if metric in ("euclidean_oblique", "cosine_oblique"):
        data = apply_oblique_transform(data, feature_columns, decay_factor)

    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
    if metric in ("euclidean_orthogonal", "euclidean_oblique"):
        return euclidean_distances(data)
    else:  # cosine
        return cosine_distances(data)


# ==============================================================================
# –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
# ==============================================================================

def load_scores_from_folder(
    folder_path: str = "basic_scores",
    specific_files: Optional[List[str]] = None
) -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π –∏–∑ CSV —Ñ–∞–π–ª–æ–≤.

    Args:
        folder_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å CSV —Ñ–∞–π–ª–∞–º–∏
        specific_files: –°–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–µ—Å–ª–∏ None - –≤—Å–µ CSV –∏–∑ –ø–∞–ø–∫–∏)

    Returns:
        DataFrame —Å –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    base = Path(folder_path).expanduser().resolve()

    if specific_files:
        files = [base / f for f in specific_files if (base / f).exists()]
    else:
        files = sorted(base.glob("*.csv"))

    if not files:
        raise FileNotFoundError(f"CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {base}")

    frames: List[pd.DataFrame] = []
    for file in files:
        try:
            frame = pd.read_csv(file)
            if "Code" not in frame.columns:
                raise KeyError(f"–§–∞–π–ª {file.name} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫—É 'Code'")
            frames.append(frame)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file}: {e}")
            continue

    if not frames:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª")

    scores = pd.concat(frames, ignore_index=True)
    scores = scores.dropna(subset=["Code"])
    scores["Code"] = scores["Code"].astype(str).str.strip()
    scores = scores[scores["Code"].str.len() > 0]
    scores = scores.drop_duplicates(subset=["Code"], keep="first")

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    feature_columns = [c for c in scores.columns if c != "Code"]
    scores[feature_columns] = scores[feature_columns].apply(
        pd.to_numeric, errors="coerce"
    )
    scores[feature_columns] = scores[feature_columns].fillna(0.0)

    return scores


def get_feature_columns(scores: pd.DataFrame) -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–∫–æ–¥—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞)."""
    return [c for c in scores.columns if c != "Code"]


# ==============================================================================
# –°–ë–û–† –î–ê–ù–ù–´–• –î–õ–Ø –ù–ê–£–ß–ù–´–• –®–ö–û–õ
# ==============================================================================

def gather_school_dataset(
    df: pd.DataFrame,
    index: Dict[str, Set[int]],
    root: str,
    scores: pd.DataFrame,
    scope: ComparisonScope,
    lineage_func: Callable,
    rows_for_func: Callable,
) -> Tuple[pd.DataFrame, pd.DataFrame, int]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π –¥–ª—è –Ω–∞—É—á–Ω–æ–π —à–∫–æ–ª—ã.

    Args:
        df: –û—Å–Ω–æ–≤–Ω–æ–π DataFrame —Å –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏—è–º–∏
        index: –ò–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞
        root: –ò–º—è —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è (–∫–æ—Ä–µ–Ω—å —à–∫–æ–ª—ã)
        scores: DataFrame —Å —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø—Ä–æ—Ñ–∏–ª—è–º–∏
        scope: "direct" - —Ç–æ–ª—å–∫–æ –ø—Ä—è–º—ã–µ –¥–∏—Å—Å–µ—Ä—Ç–∞–Ω—Ç—ã, "all" - –≤—Å–µ –ø–æ–∫–æ–ª–µ–Ω–∏—è
        lineage_func: –§—É–Ω–∫—Ü–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥–µ–Ω–µ–∞–ª–æ–≥–∏–∏
        rows_for_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å—Ç—Ä–æ–∫ –ø–æ –∏–º–µ–Ω–∏

    Returns:
        (dataset, missing_info, total_count)
    """
    author_column = "candidate.name"

    if scope == "direct":
        subset = rows_for_func(df, index, root)
    elif scope == "all":
        _, subset = lineage_func(df, index, root)
    else:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π scope: {scope}")

    if subset.empty:
        empty = pd.DataFrame(columns=list(scores.columns) + ["school", author_column])
        return empty, empty, 0

    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–¥—ã –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏–π
    working = subset[["Code", author_column]].copy()
    working["Code"] = working["Code"].astype(str).str.strip()
    working = working[working["Code"].str.len() > 0]

    codes = working["Code"].unique().tolist()

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–æ—Ñ–∏–ª—è–º–∏
    dataset = scores[scores["Code"].isin(codes)].copy()
    dataset["school"] = root
    dataset = dataset.merge(
        working.drop_duplicates(subset=["Code"]),
        on="Code",
        how="left"
    )

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö
    missing_codes = sorted(set(codes) - set(dataset["Code"]))
    missing_info = working[working["Code"].isin(missing_codes)].drop_duplicates(
        subset=["Code"]
    ).rename(columns={author_column: "candidate_name"})

    if author_column not in dataset.columns:
        dataset[author_column] = None

    return dataset, missing_info, len(codes)


# ==============================================================================
# –í–´–ß–ò–°–õ–ï–ù–ò–ï –°–ò–õ–£–≠–¢–ê
# ==============================================================================

def compute_silhouette_analysis(
    datasets: Dict[str, pd.DataFrame],
    feature_columns: List[str],
    metric: DistanceMetric,
    selected_nodes: Optional[List[str]] = None,
    decay_factor: float = 0.5,
) -> Tuple[float, np.ndarray, np.ndarray, List[str], List[str]]:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∞–Ω–∞–ª–∏–∑ —Å–∏–ª—É—ç—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª.

    Args:
        datasets: –°–ª–æ–≤–∞—Ä—å {–Ω–∞–∑–≤–∞–Ω–∏–µ_—à–∫–æ–ª—ã: DataFrame}
        feature_columns: –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        metric: –ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        selected_nodes: –í—ã–±—Ä–∞–Ω–Ω—ã–µ —É–∑–ª—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (None = –≤–µ—Å—å –±–∞–∑–∏—Å)
        decay_factor: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è –¥–ª—è –∫–æ—Å–æ—É–≥–æ–ª—å–Ω–æ–≥–æ –±–∞–∑–∏—Å–∞

    Returns:
        (overall_score, sample_scores, labels, school_order, used_columns)
    """
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —É–∑–ª–∞–º
    used_columns = filter_columns_by_nodes(feature_columns, selected_nodes)

    if not used_columns:
        raise ValueError("–ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö —à–∫–æ–ª
    all_data = []
    all_labels = []
    school_order = []

    for school_name, dataset in datasets.items():
        if dataset.empty:
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        available_cols = [c for c in used_columns if c in dataset.columns]
        if not available_cols:
            continue

        school_data = dataset[available_cols].fillna(0.0).values

        if school_data.shape[0] > 0:
            all_data.append(school_data)
            all_labels.extend([len(school_order)] * school_data.shape[0])
            school_order.append(school_name)

    if len(school_order) < 2:
        raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º—É–º 2 —à–∫–æ–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–∏–Ω –º–∞—Å—Å–∏–≤
    X = np.vstack(all_data)
    labels = np.array(all_labels)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
    if X.shape[0] < 2:
        raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

    # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
    distance_matrix = compute_distance_matrix(X, used_columns, metric, decay_factor)

    # –í—ã—á–∏—Å–ª—è–µ–º —Å–∏–ª—É—ç—Ç
    try:
        overall_score = silhouette_score(distance_matrix, labels, metric="precomputed")
        sample_scores = silhouette_samples(distance_matrix, labels, metric="precomputed")
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å–∏–ª—É—ç—Ç–∞: {e}")

    return overall_score, sample_scores, labels, school_order, used_columns


# ==============================================================================
# –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
# ==============================================================================

def create_silhouette_plot(
    sample_scores: np.ndarray,
    labels: np.ndarray,
    school_order: List[str],
    overall_score: float,
    metric_label: str,
) -> plt.Figure:
    """
    –°–æ–∑–¥–∞—ë—Ç –≥—Ä–∞—Ñ–∏–∫ —Å–∏–ª—É—ç—Ç–∞ –¥–ª—è –Ω–∞—É—á–Ω—ã—Ö —à–∫–æ–ª.

    Args:
        sample_scores: –ó–Ω–∞—á–µ–Ω–∏—è —Å–∏–ª—É—ç—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
        labels: –ú–µ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (—à–∫–æ–ª)
        school_order: –ü–æ—Ä—è–¥–æ–∫ —à–∫–æ–ª
        overall_score: –û–±—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∏–ª—É—ç—Ç–∞
        metric_label: –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞

    Returns:
        Matplotlib Figure
    """
    n_schools = len(school_order)
    fig, ax = plt.subplots(figsize=(10, max(6, n_schools * 1.5)))

    y_lower = 10
    colors = plt.cm.Set2(np.linspace(0, 1, n_schools))

    for idx, school in enumerate(school_order):
        mask = labels == idx
        cluster_scores = sample_scores[mask]

        if cluster_scores.size == 0:
            continue

        cluster_scores = np.sort(cluster_scores)
        size = cluster_scores.size
        y_upper = y_lower + size

        ax.fill_betweenx(
            np.arange(y_lower, y_upper),
            0,
            cluster_scores,
            facecolor=colors[idx],
            edgecolor=colors[idx],
            alpha=0.7,
        )

        # –ü–æ–¥–ø–∏—Å—å —à–∫–æ–ª—ã
        ax.text(
            -0.05,
            y_lower + size / 2,
            f"{school} (n={size})",
            fontsize=10,
            va="center",
            ha="right",
        )

        y_lower = y_upper + 10

    # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
    ax.axvline(
        x=overall_score,
        color="red",
        linestyle="--",
        linewidth=2,
        label=f"–°—Ä–µ–¥–Ω–∏–π —Å–∏–ª—É—ç—Ç: {overall_score:.3f}"
    )

    ax.set_xlim(-1, 1)
    ax.set_xlabel("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∏–ª—É—ç—Ç–∞", fontsize=12)
    ax.set_ylabel("–ù–∞—É—á–Ω—ã–µ —à–∫–æ–ª—ã", fontsize=12)
    ax.set_title(
        f"–ê–Ω–∞–ª–∏–∑ —Å–∏–ª—É—ç—Ç–∞ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π\n{metric_label}",
        fontsize=14,
        fontweight="bold"
    )
    ax.set_yticks([])
    ax.legend(loc="lower right", fontsize=10)
    ax.grid(axis="x", linestyle="--", alpha=0.4)

    # –¶–≤–µ—Ç–æ–≤–∞—è —à–∫–∞–ª–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
    ax.axvspan(-1, -0.25, alpha=0.1, color="red", label="–ü–ª–æ—Ö–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")
    ax.axvspan(-0.25, 0.25, alpha=0.1, color="yellow", label="–°–ª–∞–±–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")
    ax.axvspan(0.25, 0.5, alpha=0.1, color="lightgreen", label="–£–º–µ—Ä–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")
    ax.axvspan(0.5, 1, alpha=0.1, color="green", label="–•–æ—Ä–æ—à–µ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")

    fig.tight_layout()
    return fig


def create_comparison_summary(
    datasets: Dict[str, pd.DataFrame],
    feature_columns: List[str],
    school_order: List[str],
) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞—ë—Ç —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —à–∫–æ–ª.

    Args:
        datasets: –°–ª–æ–≤–∞—Ä—å –¥–∞–Ω–Ω—ã—Ö —à–∫–æ–ª
        feature_columns: –ö–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        school_order: –ü–æ—Ä—è–¥–æ–∫ —à–∫–æ–ª

    Returns:
        DataFrame —Å–æ —Å–≤–æ–¥–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
    """
    summary_data = []

    for school in school_order:
        if school not in datasets:
            continue

        data = datasets[school]
        if data.empty:
            continue

        available_cols = [c for c in feature_columns if c in data.columns]
        numeric_data = data[available_cols].fillna(0.0)

        summary_data.append({
            "–ù–∞—É—á–Ω–∞—è —à–∫–æ–ª–∞": school,
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏–π": len(data),
            "–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ –ø—Ä–æ—Ñ–∏–ª—è": numeric_data.sum(axis=1).mean(),
            "–ú–µ–¥–∏–∞–Ω–∞ —Å—É–º–º—ã –ø—Ä–æ—Ñ–∏–ª—è": numeric_data.sum(axis=1).median(),
            "–°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ": numeric_data.sum(axis=1).std(),
            "–ù–µ–Ω—É–ª–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Å—Ä–µ–¥–Ω–µ–µ)": (numeric_data > 0).sum(axis=1).mean(),
        })

    return pd.DataFrame(summary_data)


# ==============================================================================
# –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
# ==============================================================================

def interpret_silhouette_score(score: float) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —Å–∏–ª—É—ç—Ç–∞.
    """
    if score >= 0.71:
        return "üü¢ –û—Ç–ª–∏—á–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: —à–∫–æ–ª—ã –∏–º–µ—é—Ç —á—ë—Ç–∫–æ —Ä–∞–∑–ª–∏—á–∞—é—â–∏–µ—Å—è —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ñ–∏–ª–∏"
    elif score >= 0.51:
        return "üü¢ –•–æ—Ä–æ—à–µ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: —à–∫–æ–ª—ã –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è –ø–æ —Ç–µ–º–∞—Ç–∏–∫–µ"
    elif score >= 0.26:
        return "üü° –£–º–µ—Ä–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: –µ—Å—Ç—å —á–∞—Å—Ç–∏—á–Ω–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π"
    elif score >= 0:
        return "üü† –°–ª–∞–±–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: —à–∫–æ–ª—ã –∏–º–µ—é—Ç —Å—Ö–æ–∂–∏–µ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ñ–∏–ª–∏"
    else:
        return "üî¥ –ü–ª–æ—Ö–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ñ–∏–ª–∏ –ø–µ—Ä–µ–º–µ—à–∞–Ω—ã, –≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ–≤–µ—Ä–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è"
